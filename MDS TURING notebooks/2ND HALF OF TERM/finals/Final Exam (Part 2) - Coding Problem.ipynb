{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematics for Data Science\n",
    "\n",
    "## Final Exam (Part 2) - Coding Problem \n",
    "\n",
    "<i>Note: This is constitutes 10% of your Final Exam grade.</i>\n",
    "\n",
    "This notebook should be submitted <b><u>individually</u></b>.   \n",
    "\n",
    "Name:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><u>Read the instructions and questions carefully.</u></b>\n",
    "\n",
    "Do <b><u>NOT</u></b> import any other libraries aside from those below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T09:38:19.788176Z",
     "start_time": "2021-05-10T09:38:19.642015Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-14T06:47:08.439375Z",
     "iopub.status.busy": "2021-06-14T06:47:08.438764Z",
     "iopub.status.idle": "2021-06-14T06:47:09.403740Z",
     "shell.execute_reply": "2021-06-14T06:47:09.403034Z",
     "shell.execute_reply.started": "2021-06-14T06:47:08.439208Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06169621,  0.02187235, -0.01764613],\n",
       "       [-0.05147406, -0.02632783, -0.09220405],\n",
       "       [ 0.04445121, -0.00567061, -0.02593034],\n",
       "       ...,\n",
       "       [-0.01590626,  0.01728186,  0.01549073],\n",
       "       [ 0.03906215,  0.00121513, -0.02593034],\n",
       "       [-0.0730303 , -0.08141377,  0.00306441]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load the diabetes dataset\n",
    "x, y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "# Use three features\n",
    "x = x[:, [2, 3, 9]]\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Fitting a Ridge Regression Using Gradient Descent (10 pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement batch gradient descent to fit the diabetes dataset to a multiple linear regression model,\n",
    "\n",
    "\\begin{align*}\n",
    "    y &= \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_3\n",
    "\\end{align*}\n",
    "\n",
    "with squared loss (not MSE loss, but notice how they are equivalent) and ridge regularization (also known as L2 regularization),\n",
    "\n",
    "\\begin{align*}\n",
    "    J(\\hat{\\theta}_0, \\hat{\\theta}_1, \\hat{\\theta}_2, \\hat{\\theta}_3) &= \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^{3} (\\hat{\\theta}_j)^2\n",
    "\\end{align*}\n",
    "\n",
    "Note that $\\hat{\\theta}_0$ is NOT included in the penalty term.\n",
    "\n",
    "---\n",
    "\n",
    "### Interlude\n",
    "\n",
    "One of the goals of ridge regression (and regularization in general) is to reduce \"overfitting\". For linear regression, this is especially important when the features are highly correlated with each other.\n",
    "\n",
    "From a classical statistics perspective, it turns out that we can decompose the MSE statistic into <b><i>bias</b></i> and <b><i>variance</b></i> terms. Ridge regularization allows us to achieve a lower MSE by introducing a \"slight\" amount of bias in order to get a lower variance.\n",
    "\n",
    "We will revisit this concept in ACS and you will be using Ridge (and Lasso) as a regularization tool in ML! Very cool.\n",
    "\n",
    "---\n",
    "\n",
    "For this problem, set the regularization parameter $\\lambda = 1$.\n",
    "\n",
    "Print a diagnostic output for the first five iterations ($k = 0, 1, 2, 3, 4$), then print the output every 1000 iterations until convergence ($k = 1000, 2000, 3000, \\ldots$).\n",
    "\n",
    "The diagnostic output should contain the following: the iteration $k$, parameters $\\hat{\\theta}_{k}$, and loss $J$.\n",
    "\n",
    "Your solution should be <u>stable</u> and <u>exact</u> up to 4 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T06:47:09.405506Z",
     "iopub.status.busy": "2021-06-14T06:47:09.405275Z",
     "iopub.status.idle": "2021-06-14T06:47:09.409048Z",
     "shell.execute_reply": "2021-06-14T06:47:09.408311Z",
     "shell.execute_reply.started": "2021-06-14T06:47:09.405475Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 0 -- theta_k[0] = 1.0000 -- theta_k[1] = 1.0000 -- theta_k[2] = 1.0000 -- theta_k[3] = 1.0000 -- J = 12712318.5496\n",
      "k = 1 -- theta_k[0] = 134.6020 -- theta_k[1] = 2.8933 -- theta_k[2] = 2.4239 -- theta_k[3] = 2.2329 -- J = 2745188.1244\n",
      "k = 2 -- theta_k[0] = 150.0998 -- theta_k[1] = 4.7769 -- theta_k[2] = 3.8397 -- theta_k[3] = 3.4583 -- J = 2604131.4706\n",
      "k = 3 -- theta_k[0] = 151.8976 -- theta_k[1] = 6.6510 -- theta_k[2] = 5.2473 -- theta_k[3] = 4.6762 -- J = 2595370.4540\n",
      "k = 4 -- theta_k[0] = 152.1061 -- theta_k[1] = 8.5155 -- theta_k[2] = 6.6469 -- theta_k[3] = 5.8866 -- J = 2588464.7590\n",
      "k = 1000 -- theta_k[0] = 152.1335 -- theta_k[1] = 384.6549 -- theta_k[2] = 244.0755 -- theta_k[3] = 188.5413 -- J = 1960916.9497\n",
      "k = 2000 -- theta_k[0] = 152.1335 -- theta_k[1] = 390.1390 -- theta_k[2] = 243.9078 -- theta_k[3] = 186.2808 -- J = 1960852.2453\n",
      "k = 3000 -- theta_k[0] = 152.1335 -- theta_k[1] = 390.3207 -- theta_k[2] = 243.8628 -- theta_k[3] = 186.1551 -- J = 1960852.1567\n",
      "k = 4000 -- theta_k[0] = 152.1335 -- theta_k[1] = 390.3278 -- theta_k[2] = 243.8609 -- theta_k[3] = 186.1500 -- J = 1960852.1565\n",
      "k = 5000 -- theta_k[0] = 152.1335 -- theta_k[1] = 390.3281 -- theta_k[2] = 243.8608 -- theta_k[3] = 186.1498 -- J = 1960852.1565\n",
      "k = 6000 -- theta_k[0] = 152.1335 -- theta_k[1] = 390.3281 -- theta_k[2] = 243.8608 -- theta_k[3] = 186.1498 -- J = 1960852.1565\n",
      "k = 7000 -- theta_k[0] = 152.1335 -- theta_k[1] = 390.3281 -- theta_k[2] = 243.8608 -- theta_k[3] = 186.1498 -- J = 1960852.1565\n",
      "k = 8000 -- theta_k[0] = 152.1335 -- theta_k[1] = 390.3281 -- theta_k[2] = 243.8608 -- theta_k[3] = 186.1498 -- J = 1960852.1565\n",
      "k = 9000 -- theta_k[0] = 152.1335 -- theta_k[1] = 390.3281 -- theta_k[2] = 243.8608 -- theta_k[3] = 186.1498 -- J = 1960852.1565\n"
     ]
    }
   ],
   "source": [
    "# Use the following variables\n",
    "theta_k = np.array([1, 1, 1, 1])\n",
    "lam = 1\n",
    "lr = 0.001\n",
    "\n",
    "# Your code here\n",
    "\n",
    "x=x.T\n",
    "\n",
    "def J(theta, x, y):\n",
    "    term1 = sum((y-(theta[0] + theta[1]*x[0] + theta[2]*x[1] + theta[3]*x[2]))**2)\n",
    "    term2 = lam*(theta[1]**2 + theta[2]**2 + theta[3]**2)\n",
    "    return term1 + term2\n",
    "\n",
    "def grad_T0(theta, x, y):\n",
    "    return -2*sum((y-(theta[0] + theta[1]*x[0] + theta[2]*x[1] + theta[3]*x[2])))\n",
    "\n",
    "def grad_T1(theta, x, y):\n",
    "    return -2*sum(x[0]*(y-(theta[0] + theta[1]*x[0] + theta[2]*x[1] + theta[3]*x[2]))) + 2*lam*theta[1]\n",
    "\n",
    "def grad_T2(theta, x, y):\n",
    "    return -2*sum(x[1]*(y-(theta[0] + theta[1]*x[0] + theta[2]*x[1] + theta[3]*x[2]))) + 2*lam*theta[2]\n",
    "\n",
    "def grad_T3(theta, x, y):\n",
    "    return -2*sum(x[2]*(y-(theta[0] + theta[1]*x[0] + theta[2]*x[1] + theta[3]*x[2]))) + 2*lam*theta[3]\n",
    "\n",
    "\n",
    "for k in range(0, 10000):\n",
    "    if ((k<5) or (k % 1000 == 0)):\n",
    "        print(\"k = %d --\" %k,\"theta_k[0] = %.4f --\" %theta_k[0],\"theta_k[1] = %.4f --\" %theta_k[1], \"theta_k[2] = %.4f --\" %theta_k[2], \"theta_k[3] = %.4f --\" %theta_k[3], \"J = %.4f\" %J(theta_k,x,y))\n",
    "    theta_k = theta_k - lr*np.array([grad_T0(theta_k,x,y), grad_T1(theta_k,x,y), grad_T2(theta_k,x,y), grad_T3(theta_k,x,y)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_theta = np.array([152.1335, 390.3281, 243.8608, 186.1498])\n",
    "J = 1960852.1565"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
