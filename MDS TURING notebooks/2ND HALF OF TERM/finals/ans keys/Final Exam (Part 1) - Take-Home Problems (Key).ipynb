{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematics for Data Science\n",
    "\n",
    "## Final Exam (Part 1) - Take-Home Problems\n",
    "\n",
    "#### Deadline: 11:59pm June 13, 2020 (Sunday)\n",
    "\n",
    "This midterm should be submitted <b><u>individually</u></b>.   \n",
    "\n",
    "Name:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><u>Read the instructions and questions carefully.</u></b>\n",
    "\n",
    "Do <b><u>NOT</u></b> import any other libraries aside from those below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:25:22.938203Z",
     "iopub.status.busy": "2021-06-22T07:25:22.937652Z",
     "iopub.status.idle": "2021-06-22T07:25:24.650185Z",
     "shell.execute_reply": "2021-06-22T07:25:24.649273Z",
     "shell.execute_reply.started": "2021-06-22T07:25:22.938056Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## I. Stochastic Gradient Descent (2 pts.)\n",
    "\n",
    "The major drawback of batch gradient descent is that it is usually computationally expensive to calculate a gradient update using the entire dataset. Instead, most optimization algorithms in deep learning use so-called <b>minibatch</b> or <b>minibatch stochastic</b> methods, where gradients are calculated on a random sample of the dataset.\n",
    "\n",
    "In this section, your goal is to implement <b>stochastic gradient descent</b> (SGD) with momentum. Click [`here`](https://www.deeplearningbook.org/contents/optimization.html) for more details.\n",
    "\n",
    "Once again, we will fit a simple linear regression model:\n",
    "\n",
    "\\begin{align*}\n",
    "    y = \\theta_0 + \\theta_1 x\n",
    "\\end{align*}\n",
    "\n",
    "to the `diabetes` dataset in `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:25:24.651394Z",
     "iopub.status.busy": "2021-06-22T07:25:24.651231Z",
     "iopub.status.idle": "2021-06-22T07:25:24.806606Z",
     "shell.execute_reply": "2021-06-22T07:25:24.805647Z",
     "shell.execute_reply.started": "2021-06-22T07:25:24.651373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the diabetes dataset\n",
    "x, y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "# Use only one feature\n",
    "x = x[:, 2]\n",
    "\n",
    "# Plot the data\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1. (2 pts.)\n",
    "\n",
    "Implment SGD with a learning rate $\\epsilon_k$ that randomly samples (w/o replacement) a minibatch of size $m$ from the dataset every iteration.\n",
    "\n",
    "Adjust the learning rate at each iteration $k$ so that it decays linearly until iteration $\\tau$:\n",
    "\n",
    "\\begin{align}\n",
    "    \\epsilon_k &= (1-\\alpha)\\epsilon_0 + \\alpha \\epsilon_\\tau\n",
    "\\end{align}\n",
    "\n",
    "where $\\alpha = \\frac{k}{\\tau}$. After iteration $\\tau$, leave $\\epsilon$ constant.\n",
    "\n",
    "Similar to the previous exam, use SGD to estimate the parameters $\\hat{\\theta}_0$ and $\\hat{\\theta}_1$ by minimizing the <b><i>mean squared error</b></i> (MSE):\n",
    "\n",
    "\\begin{align*}\n",
    "    J(\\hat{\\theta}_0, \\hat{\\theta}_1) &= \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "\\end{align*}\n",
    "\n",
    "Print a diagnostic output for the first five iterations $k = 0, 1, 2, 3, 4$, then print the output every 100 iterations $k = 100, 200, 300 , \\ldots, 5000$.\n",
    "\n",
    "The diagnostic output should contain the following: the iteration $k$, learning rate $\\epsilon_k$, parameters $\\hat{\\theta}_{k,0}, \\hat{\\theta}_{k,1}$, and MSE $J(\\hat{\\theta}_{k,0}, \\hat{\\theta}_{k,1})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:25:24.808063Z",
     "iopub.status.busy": "2021-06-22T07:25:24.807832Z",
     "iopub.status.idle": "2021-06-22T07:25:25.658770Z",
     "shell.execute_reply": "2021-06-22T07:25:25.657747Z",
     "shell.execute_reply.started": "2021-06-22T07:25:24.808041Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 0 -- e = 0.5000 -- theta_k[0] = 1.0000 -- theta_k[1] = 1.0000 -- J(theta_k) = 28766.9211\n",
      "k = 1 -- e = 0.4999 -- theta_k[0] = 147.2669 -- theta_k[1] = 1.5860 -- J(theta_k) = 5946.7607\n",
      "k = 2 -- e = 0.4998 -- theta_k[0] = 158.1739 -- theta_k[1] = 3.6617 -- J(theta_k) = 5950.6702\n",
      "k = 3 -- e = 0.4998 -- theta_k[0] = 158.9536 -- theta_k[1] = 5.6730 -- J(theta_k) = 5952.1000\n",
      "k = 4 -- e = 0.4997 -- theta_k[0] = 152.3173 -- theta_k[1] = 7.9421 -- J(theta_k) = 5895.9413\n",
      "k = 100 -- e = 0.4918 -- theta_k[0] = 158.0382 -- theta_k[1] = 192.7383 -- J(theta_k) = 5220.7757\n",
      "k = 200 -- e = 0.4837 -- theta_k[0] = 144.1894 -- theta_k[1] = 340.5908 -- J(theta_k) = 4792.2340\n",
      "k = 300 -- e = 0.4755 -- theta_k[0] = 150.6435 -- theta_k[1] = 462.8226 -- J(theta_k) = 4428.4050\n",
      "k = 400 -- e = 0.4673 -- theta_k[0] = 153.2561 -- theta_k[1] = 557.1520 -- J(theta_k) = 4239.8755\n",
      "k = 500 -- e = 0.4592 -- theta_k[0] = 159.0225 -- theta_k[1] = 634.2359 -- J(theta_k) = 4162.6908\n",
      "k = 600 -- e = 0.4510 -- theta_k[0] = 153.5137 -- theta_k[1] = 689.6024 -- J(theta_k) = 4045.1062\n",
      "k = 700 -- e = 0.4428 -- theta_k[0] = 158.0748 -- theta_k[1] = 742.3135 -- J(theta_k) = 4022.8129\n",
      "k = 800 -- e = 0.4347 -- theta_k[0] = 150.9359 -- theta_k[1] = 779.7006 -- J(theta_k) = 3957.0715\n",
      "k = 900 -- e = 0.4265 -- theta_k[0] = 155.1846 -- theta_k[1] = 809.8994 -- J(theta_k) = 3943.8162\n",
      "k = 1000 -- e = 0.4183 -- theta_k[0] = 148.2445 -- theta_k[1] = 834.5785 -- J(theta_k) = 3935.4272\n",
      "k = 1100 -- e = 0.4102 -- theta_k[0] = 153.9500 -- theta_k[1] = 854.8826 -- J(theta_k) = 3913.9832\n",
      "k = 1200 -- e = 0.4020 -- theta_k[0] = 155.7769 -- theta_k[1] = 870.6367 -- J(theta_k) = 3917.7789\n",
      "k = 1300 -- e = 0.3938 -- theta_k[0] = 155.7576 -- theta_k[1] = 885.1217 -- J(theta_k) = 3912.9485\n",
      "k = 1400 -- e = 0.3857 -- theta_k[0] = 157.0930 -- theta_k[1] = 894.8104 -- J(theta_k) = 3921.8046\n",
      "k = 1500 -- e = 0.3775 -- theta_k[0] = 146.8143 -- theta_k[1] = 903.4461 -- J(theta_k) = 3923.5349\n",
      "k = 1600 -- e = 0.3693 -- theta_k[0] = 156.4925 -- theta_k[1] = 910.0378 -- J(theta_k) = 3912.9692\n",
      "k = 1700 -- e = 0.3612 -- theta_k[0] = 154.8457 -- theta_k[1] = 917.5127 -- J(theta_k) = 3900.1181\n",
      "k = 1800 -- e = 0.3530 -- theta_k[0] = 157.1227 -- theta_k[1] = 921.4307 -- J(theta_k) = 3917.1231\n",
      "k = 1900 -- e = 0.3448 -- theta_k[0] = 149.1452 -- theta_k[1] = 926.2107 -- J(theta_k) = 3900.6068\n",
      "k = 2000 -- e = 0.3367 -- theta_k[0] = 157.6548 -- theta_k[1] = 930.4947 -- J(theta_k) = 3921.7535\n",
      "k = 2100 -- e = 0.3285 -- theta_k[0] = 155.3492 -- theta_k[1] = 932.7245 -- J(theta_k) = 3901.4291\n",
      "k = 2200 -- e = 0.3203 -- theta_k[0] = 158.8365 -- theta_k[1] = 935.0976 -- J(theta_k) = 3935.8526\n",
      "k = 2300 -- e = 0.3122 -- theta_k[0] = 158.3238 -- theta_k[1] = 936.5328 -- J(theta_k) = 3929.1534\n",
      "k = 2400 -- e = 0.3040 -- theta_k[0] = 153.3975 -- theta_k[1] = 938.7129 -- J(theta_k) = 3892.3144\n",
      "k = 2500 -- e = 0.2958 -- theta_k[0] = 152.4278 -- theta_k[1] = 940.7488 -- J(theta_k) = 3890.7139\n",
      "k = 2600 -- e = 0.2877 -- theta_k[0] = 154.0272 -- theta_k[1] = 941.9006 -- J(theta_k) = 3894.1711\n",
      "k = 2700 -- e = 0.2795 -- theta_k[0] = 153.6161 -- theta_k[1] = 941.3180 -- J(theta_k) = 3892.8038\n",
      "k = 2800 -- e = 0.2713 -- theta_k[0] = 152.6957 -- theta_k[1] = 943.4305 -- J(theta_k) = 3890.8543\n",
      "k = 2900 -- e = 0.2632 -- theta_k[0] = 153.7759 -- theta_k[1] = 943.6395 -- J(theta_k) = 3893.2302\n",
      "k = 3000 -- e = 0.2550 -- theta_k[0] = 154.5089 -- theta_k[1] = 943.5415 -- J(theta_k) = 3896.1776\n",
      "k = 3100 -- e = 0.2468 -- theta_k[0] = 154.8247 -- theta_k[1] = 946.5671 -- J(theta_k) = 3897.7179\n",
      "k = 3200 -- e = 0.2387 -- theta_k[0] = 156.3349 -- theta_k[1] = 947.2490 -- J(theta_k) = 3908.1194\n",
      "k = 3300 -- e = 0.2305 -- theta_k[0] = 155.4583 -- theta_k[1] = 946.8297 -- J(theta_k) = 3901.5261\n",
      "k = 3400 -- e = 0.2223 -- theta_k[0] = 152.4627 -- theta_k[1] = 947.6484 -- J(theta_k) = 3890.5722\n",
      "k = 3500 -- e = 0.2142 -- theta_k[0] = 151.1647 -- theta_k[1] = 947.3774 -- J(theta_k) = 3891.4046\n",
      "k = 3600 -- e = 0.2060 -- theta_k[0] = 151.7029 -- theta_k[1] = 946.4609 -- J(theta_k) = 3890.6620\n",
      "k = 3700 -- e = 0.1978 -- theta_k[0] = 148.7944 -- theta_k[1] = 947.9321 -- J(theta_k) = 3901.6113\n",
      "k = 3800 -- e = 0.1897 -- theta_k[0] = 150.9708 -- theta_k[1] = 948.2243 -- J(theta_k) = 3891.8117\n",
      "k = 3900 -- e = 0.1815 -- theta_k[0] = 153.3033 -- theta_k[1] = 948.0983 -- J(theta_k) = 3891.8291\n",
      "k = 4000 -- e = 0.1733 -- theta_k[0] = 148.1013 -- theta_k[1] = 948.3542 -- J(theta_k) = 3906.7177\n",
      "k = 4100 -- e = 0.1652 -- theta_k[0] = 150.7912 -- theta_k[1] = 948.2380 -- J(theta_k) = 3892.2615\n",
      "k = 4200 -- e = 0.1570 -- theta_k[0] = 151.1608 -- theta_k[1] = 947.5044 -- J(theta_k) = 3891.4111\n",
      "k = 4300 -- e = 0.1488 -- theta_k[0] = 151.0937 -- theta_k[1] = 947.5333 -- J(theta_k) = 3891.5460\n",
      "k = 4400 -- e = 0.1407 -- theta_k[0] = 149.2516 -- theta_k[1] = 947.9141 -- J(theta_k) = 3898.7668\n",
      "k = 4500 -- e = 0.1325 -- theta_k[0] = 147.7762 -- theta_k[1] = 948.3588 -- J(theta_k) = 3909.4449\n",
      "k = 4600 -- e = 0.1243 -- theta_k[0] = 149.5381 -- theta_k[1] = 948.9004 -- J(theta_k) = 3897.1930\n",
      "k = 4700 -- e = 0.1162 -- theta_k[0] = 152.3626 -- theta_k[1] = 948.7498 -- J(theta_k) = 3890.5101\n",
      "k = 4800 -- e = 0.1080 -- theta_k[0] = 154.0260 -- theta_k[1] = 949.0604 -- J(theta_k) = 3894.0385\n",
      "k = 4900 -- e = 0.0998 -- theta_k[0] = 152.6314 -- theta_k[1] = 949.0813 -- J(theta_k) = 3890.7048\n",
      "k = 5000 -- e = 0.0917 -- theta_k[0] = 155.2595 -- theta_k[1] = 948.7553 -- J(theta_k) = 3900.2296\n"
     ]
    }
   ],
   "source": [
    "# Use the following variables\n",
    "np.random.seed(1)\n",
    "m = 100\n",
    "tau = 6000\n",
    "learning_rate_0 = 0.5\n",
    "learning_rate_tau = 0.01\n",
    "theta_k = np.array([1, 1])\n",
    "\n",
    "# Your code here\n",
    "\n",
    "def sample_minibatch(x, y, m):\n",
    "    random_idx = np.random.choice(range(x.shape[0]), size=m, replace=False)\n",
    "    return x[random_idx], y[random_idx]\n",
    "\n",
    "def J(theta, x, y):\n",
    "    return np.mean((y - (theta[0] + theta[1]*x))**2)\n",
    "\n",
    "def SLR(x):\n",
    "    return 152.1335 + 949.4352*x\n",
    "\n",
    "for k in range(0, 5001):\n",
    "    \n",
    "    ### Adjust learning rate\n",
    "    if k <= tau:\n",
    "        alpha = k/tau\n",
    "        learning_rate = (1-alpha)*learning_rate_0 + alpha*learning_rate_tau\n",
    "    \n",
    "    ### Diagnostics\n",
    "    if k < 5:\n",
    "        print(\"k = %d --\" %k,\"e = %.4f --\" %learning_rate,\"theta_k[0] = %.4f --\" %theta_k[0],\"theta_k[1] = %.4f --\" %theta_k[1], \"J(theta_k) = %.4f\" %J(theta_k, x, y))\n",
    "    elif k % 100 == 0:\n",
    "        print(\"k = %d --\" %k,\"e = %.4f --\" %learning_rate,\"theta_k[0] = %.4f --\" %theta_k[0],\"theta_k[1] = %.4f --\" %theta_k[1], \"J(theta_k) = %.4f\" %J(theta_k, x, y))\n",
    "    #else:\n",
    "    #    break\n",
    "    \n",
    "    ### Sample minibatch\n",
    "    x_mini, y_mini = sample_minibatch(x, y, m)\n",
    "    \n",
    "    ### Gradient update\n",
    "    theta_k = theta_k - learning_rate*np.array([np.mean(-2*y_mini + 2*theta_k[0] + 2*theta_k[1]*x_mini), np.mean(-2*y_mini*x_mini + 2*theta_k[0]*x_mini + 2*theta_k[1]*x_mini**2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## II. PageRank (10 pts.)\n",
    "\n",
    "[`PageRank`](https://en.wikipedia.org/wiki/PageRank) is an algorithm used to rank webpages and is an important research topic in Search Engine Optimization (SEO). Originally developed by [`Larry Page`](https://en.wikipedia.org/wiki/Larry_Page) and [`Sergey Brin`](https://en.wikipedia.org/wiki/Sergey_Brin), the founders of Google, some refer to it to as the [`25 Billion Dollar Eigenvector`](https://www.rose-hulman.edu/~bryan/googleFinalVersionFixed.pdf). It was the pioneering method used by Google to determine a webpage's relevenace or importance. Very cool.\n",
    "\n",
    "We begin with a simple model of the [`World Wide Web`](https://en.wikipedia.org/wiki/World_Wide_Web) that consists of six webpages:\n",
    "\n",
    "<img src = \"fig1.png\" width = \"300\"/>\n",
    "\n",
    "Each arrow corresponds to a hyperlink that a user can click on to bring them to some corresponding destination webpage.\n",
    "\n",
    "Your goal is to rank these pages and display them to the users of a search engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1. (0.5 pts.)\n",
    "\n",
    "Given that a user is on a particular page, assume that he clicks on a random link with uniform probability. \n",
    "\n",
    "Note that only Page 1 has a self-referential link (i.e. for the other webpages, the user <b><u>must</b></u> move to another page).\n",
    "\n",
    "Construct a probability transition matrix $A$ based on the graph above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:25:25.660809Z",
     "iopub.status.busy": "2021-06-22T07:25:25.660614Z",
     "iopub.status.idle": "2021-06-22T07:25:25.668830Z",
     "shell.execute_reply": "2021-06-22T07:25:25.667870Z",
     "shell.execute_reply.started": "2021-06-22T07:25:25.660784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.     0.     0.     0.5    0.     0.    ]\n",
      " [0.     0.     1.     0.5    0.3333 0.5   ]\n",
      " [0.     1.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.3333 0.    ]\n",
      " [0.     0.     0.     0.     0.     0.5   ]\n",
      " [0.     0.     0.     0.     0.3333 0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# Insert code here\n",
    "\n",
    "A = np.array([[1, 0, 0, 1/2, 0, 0],\n",
    "              [0, 0, 1, 1/2, 1/3, 1/2],\n",
    "              [0, 1, 0, 0, 0, 0],\n",
    "              [0, 0, 0, 0, 1/3, 0],\n",
    "              [0, 0, 0, 0, 0, 1/2],\n",
    "              [0, 0, 0, 0, 1/3, 0]])\n",
    "\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. (1 pts.)\n",
    "\n",
    "What are the two properties that a matrix must have in order to be considered a valid probablity transition matrix (and by extension, a valid Markov chain)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer.\n",
    "\n",
    "1) $\\sum_{i = 1}^{n} a_{ij} = 1$, i.e. the columns must sum to 1.\n",
    "\n",
    "2) $0 \\leq a_{ij} \\leq 1$, i.e. every element must be from 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3. (1 pts.)\n",
    "\n",
    "Based on the graph alone, you may have noticed that it is possible for a user that is randomly clicking links to eventually become \"stuck\".\n",
    "\n",
    "What are the two situations in which a user can become \"stuck\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer.\n",
    "\n",
    "1) Once a user reaches Page 1, they are stuck.\n",
    "\n",
    "2) Once a user reaches Page 2, they are stuck in a cycle between Page 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4. (0.5 pts.)\n",
    "\n",
    "Suppose that a user starts at Page 6.\n",
    "\n",
    "Calculate the probability distribution vector at time step $k = 100$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:25:25.669995Z",
     "iopub.status.busy": "2021-06-22T07:25:25.669744Z",
     "iopub.status.idle": "2021-06-22T07:25:25.676435Z",
     "shell.execute_reply": "2021-06-22T07:25:25.675598Z",
     "shell.execute_reply.started": "2021-06-22T07:25:25.669972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.2 0.7 0.  0.  0. ]\n",
      "[0.1 0.7 0.2 0.  0.  0. ]\n",
      "[0.1 0.2 0.7 0.  0.  0. ]\n",
      "[0.1 0.7 0.2 0.  0.  0. ]\n"
     ]
    }
   ],
   "source": [
    "# Insert code here\n",
    "\n",
    "x_0 = np.array([0, 0, 0, 0, 0, 1])\n",
    "\n",
    "x_k = np.linalg.matrix_power(A, 100).dot(x_0)\n",
    "\n",
    "print(x_k)\n",
    "\n",
    "x_k = A.dot(x_k)\n",
    "\n",
    "print(x_k)\n",
    "\n",
    "x_k = A.dot(x_k)\n",
    "\n",
    "print(x_k)\n",
    "\n",
    "x_k = A.dot(x_k)\n",
    "\n",
    "print(x_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5. (1 pts.)\n",
    "\n",
    "Calculate $\\lim_{k \\rightarrow \\infty} A^k$. \n",
    "\n",
    "First when $k$ is even, then when $k$ is odd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:25:25.677873Z",
     "iopub.status.busy": "2021-06-22T07:25:25.677655Z",
     "iopub.status.idle": "2021-06-22T07:25:25.683249Z",
     "shell.execute_reply": "2021-06-22T07:25:25.682517Z",
     "shell.execute_reply.started": "2021-06-22T07:25:25.677846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  0.  0.  0.5 0.2 0.1]\n",
      " [0.  1.  0.  0.  0.4 0.2]\n",
      " [0.  0.  1.  0.5 0.4 0.7]\n",
      " [0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0. ]]\n",
      "[[1.  0.  0.  0.5 0.2 0.1]\n",
      " [0.  0.  1.  0.5 0.4 0.7]\n",
      " [0.  1.  0.  0.  0.4 0.2]\n",
      " [0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "# Insert code here\n",
    "\n",
    "print(np.linalg.matrix_power(A, 100))\n",
    "print(np.linalg.matrix_power(A, 101))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6. (1 pts.)\n",
    "\n",
    "Compute the eigenvalues and eigenvectors of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:25:26.400053Z",
     "iopub.status.busy": "2021-06-22T07:25:26.399612Z",
     "iopub.status.idle": "2021-06-22T07:25:26.408249Z",
     "shell.execute_reply": "2021-06-22T07:25:26.407342Z",
     "shell.execute_reply.started": "2021-06-22T07:25:26.400004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.      1.     -1.      0.      0.4082 -0.4082]\n",
      "[[ 1.      0.      0.     -0.4082 -0.3076 -0.173 ]\n",
      " [ 0.      0.7071 -0.7071  0.     -0.2512  0.1412]\n",
      " [ 0.      0.7071  0.7071 -0.4082 -0.6152 -0.3459]\n",
      " [ 0.      0.      0.      0.8165  0.364   0.4871]\n",
      " [ 0.      0.      0.      0.      0.4459 -0.5966]\n",
      " [ 0.      0.      0.      0.      0.364   0.4871]]\n"
     ]
    }
   ],
   "source": [
    "# Insert code here\n",
    "\n",
    "eig, vec = np.linalg.eig(A)\n",
    "\n",
    "print(eig)\n",
    "print(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7. (1 pts.)\n",
    "\n",
    "Based on the discussion and your answers so far, what can you say about the stationary distribution of $A$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer.\n",
    "\n",
    "(Answer in 1 to 2 sentences ONLY)\n",
    "\n",
    "There are multiple stationary distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interlude\n",
    "\n",
    "Obviously, someone browsing the internet doesn't get \"stuck\". In fact, we don't always click links when surfing the net. Ocassionally, we can type the URL of a website directly into the address bar.\n",
    "\n",
    "We can model this behavior as a new probability transition matrix,\n",
    "\n",
    "\\begin{align}\n",
    "    B &= \\begin{bmatrix}\n",
    "            1/6 & 1/6 & 1/6 & 1/6 & 1/6 & 1/6\\\\\n",
    "            1/6 & 1/6 & 1/6 & 1/6 & 1/6 & 1/6\\\\\n",
    "            1/6 & 1/6 & 1/6 & 1/6 & 1/6 & 1/6\\\\\n",
    "            1/6 & 1/6 & 1/6 & 1/6 & 1/6 & 1/6\\\\\n",
    "            1/6 & 1/6 & 1/6 & 1/6 & 1/6 & 1/6\\\\\n",
    "            1/6 & 1/6 & 1/6 & 1/6 & 1/6 & 1/6\n",
    "         \\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "Basically, the matrix says that at any page we can jump to any other page (including itself) chosen uniformly at random.\n",
    "\n",
    "We can now combine the behaviors modeled by $A$ and $B$ as a mixture of two Markov chains,\n",
    "\n",
    "\\begin{align}\n",
    "    C &= (1 - \\gamma)A + \\gamma B\n",
    "\\end{align}\n",
    "\n",
    "where the $\\gamma$ parameter is called the <b><u>damping factor</b></u>. \n",
    "\n",
    "The new Markov chain $C$ says that with probability $1 - \\gamma$ a user clicks on a random link and that with probability $\\gamma$ a user types directly into the address bar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8. (1 pts.)\n",
    "\n",
    "For this exercise, set $\\gamma = 0.1$.\n",
    "\n",
    "Construct the probability transition matrix of our new Markov chain $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:25:27.989217Z",
     "iopub.status.busy": "2021-06-22T07:25:27.988781Z",
     "iopub.status.idle": "2021-06-22T07:25:27.999798Z",
     "shell.execute_reply": "2021-06-22T07:25:27.998880Z",
     "shell.execute_reply.started": "2021-06-22T07:25:27.989167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9167 0.0167 0.0167 0.4667 0.0167 0.0167]\n",
      " [0.0167 0.0167 0.9167 0.4667 0.3167 0.4667]\n",
      " [0.0167 0.9167 0.0167 0.0167 0.0167 0.0167]\n",
      " [0.0167 0.0167 0.0167 0.0167 0.3167 0.0167]\n",
      " [0.0167 0.0167 0.0167 0.0167 0.0167 0.4667]\n",
      " [0.0167 0.0167 0.0167 0.0167 0.3167 0.0167]]\n"
     ]
    }
   ],
   "source": [
    "# Insert code here\n",
    "\n",
    "B = np.array([[1/6, 1/6, 1/6, 1/6, 1/6, 1/6],\n",
    "              [1/6, 1/6, 1/6, 1/6, 1/6, 1/6],\n",
    "              [1/6, 1/6, 1/6, 1/6, 1/6, 1/6],\n",
    "              [1/6, 1/6, 1/6, 1/6, 1/6, 1/6],\n",
    "              [1/6, 1/6, 1/6, 1/6, 1/6, 1/6],\n",
    "              [1/6, 1/6, 1/6, 1/6, 1/6, 1/6]])\n",
    "\n",
    "C = 0.9*A + 0.1*B\n",
    "\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1. (1 pts.)\n",
    "\n",
    "Compute the eigenvalues and eigenvectors of $C$. No need to rescale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:25:28.734670Z",
     "iopub.status.busy": "2021-06-22T07:25:28.734226Z",
     "iopub.status.idle": "2021-06-22T07:25:28.742884Z",
     "shell.execute_reply": "2021-06-22T07:25:28.741821Z",
     "shell.execute_reply.started": "2021-06-22T07:25:28.734619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.      0.9    -0.9     0.3674 -0.3674  0.    ]\n",
      "[[ 0.5218  0.8165  0.      0.3076 -0.173   0.4082]\n",
      " [ 0.6153 -0.4082  0.7071  0.2512  0.1412 -0.    ]\n",
      " [ 0.5849 -0.4082 -0.7071  0.6152 -0.3459  0.4082]\n",
      " [ 0.0468  0.     -0.     -0.364   0.4871 -0.8165]\n",
      " [ 0.0522  0.     -0.     -0.4459 -0.5966  0.    ]\n",
      " [ 0.0468  0.     -0.     -0.364   0.4871  0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# Insert code here\n",
    "\n",
    "eig, vec = np.linalg.eig(C)\n",
    "\n",
    "print(eig)\n",
    "print(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q10. (1 pts.)\n",
    "\n",
    "Without using your answer in Q9, calculate the stationary distribution numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:25:29.488980Z",
     "iopub.status.busy": "2021-06-22T07:25:29.488539Z",
     "iopub.status.idle": "2021-06-22T07:25:29.496256Z",
     "shell.execute_reply": "2021-06-22T07:25:29.495171Z",
     "shell.execute_reply.started": "2021-06-22T07:25:29.488930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2794 0.3294 0.3132 0.025  0.0279 0.025 ]\n"
     ]
    }
   ],
   "source": [
    "# Insert code here\n",
    "\n",
    "x_0 = np.array([0, 0, 0, 0, 0, 1])\n",
    "\n",
    "x_k = np.linalg.matrix_power(C, 100).dot(x_0)\n",
    "\n",
    "print(x_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q11. (0.5 pts.)\n",
    "\n",
    "Based on the stationary distribution you've calculated in Q10, rank the webpages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer.\n",
    "\n",
    "Search Results:\n",
    "\n",
    "Page 2\n",
    "\n",
    "Page 3\n",
    "\n",
    "Page 1\n",
    "\n",
    "Page 5\n",
    "\n",
    "Page 4\n",
    "\n",
    "Page 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q12. (0.5 pts.)\n",
    "\n",
    "Based on your answers in Q10 and Q11, why would it make sense for a search engine to rank pages this way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer.\n",
    "\n",
    "(Answer in 2 to 3 sentences ONLY)\n",
    "\n",
    "A search engine can use the stationary distribution as a prediction of where users will end up going if they were randomly surfing the web. Therefore, ranking webpages by probability lets the search engine direct users to more relevant pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## III. Utility Maximization with Budget Constraints (2 pts.)\n",
    "\n",
    "In the fields of economics, decision theory, control theory, and AI modeling, a [`utility function`](https://en.wikipedia.org/wiki/Utility) is a model that is used to represent an agent's preferences. This agent could be a person, a firm, or even a robot. The goal of this agent is to maximize it's utility, which can be thought of as a proxy for things like wealth, happiness, wellbeing, etc.\n",
    "\n",
    "Essentially, the utility function summarizes all your objectives and preferences into a function and allows us to setup a mathematical framework (in this case, constrained optimization) that we can use to determine what an agent's optimal choices should be. We can also have constraints on what an agent is allowed or not allowed to do, represented as equality or inequality constraints.\n",
    "\n",
    "Examples of utility functions with constraints include the following: \n",
    "- An investor's utility function could be setup as the profit he would make if he invests in the stock market, subject to constraints on his wealth.\n",
    "- An astronaut piloting a space shuttle could setup a utility function to represent the amount of time it would take to go to the moon (as a function of his trajectory), subject to the amount of rocket fuel his space shuttle has left.\n",
    "- A chess AI's utility function could be setup as a random variable representing the AI's probability of winning the game in the next $n$ moves, subject to the rules of chess, valid moves, the past moves of both players, etc.\n",
    "- And many more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1. (1 pts.)\n",
    "\n",
    "Consider a worker that is trying to decide how much time he should spend between working and leisure. Obviously, the worker gets utility from leisure (e.g. relaxing, socializing with friends, playing video games, etc.), but he also gets utility from working (i.e. he earns money to buy the things he needs and wants).\n",
    "\n",
    "In general, his utility function is some $U(W, L)$. For this problem, we'll use the [`Cobb-Douglas`](https://en.wikipedia.org/wiki/Cobb–Douglas_production_function) utility function with parameters $\\alpha = 2/3$ and $\\beta = 1/3$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\max_{W,L} U(W, L) = W^{2/3}L^{1/3}\n",
    "\\end{equation}\n",
    "\n",
    "Obviously, the work-leisure trade-off has a constraint: there are only 24 hours in a day. So the above objective is subject to\n",
    "\n",
    "\\begin{align}\n",
    "    W + L = 24\n",
    "\\end{align}\n",
    "\n",
    "Setup the Lagrangian function and the first order conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer.\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathcal{L}(W, L, \\lambda) &= W^{2/3}L^{1/3} - \\lambda(W + L - 24)\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "    \\frac{\\partial \\mathcal{L}}{\\partial W} &= \\frac{2}{3}W^{-1/3}L^{1/3} - \\lambda = 0\\\\\n",
    "    \\frac{\\partial \\mathcal{L}}{\\partial L} &= \\frac{1}{3}W^{2/3}L^{-2/3} - \\lambda = 0\\\\\n",
    "    \\frac{\\partial \\mathcal{L}}{\\partial \\lambda} &= W + L - 24 = 0\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1. (2 pts.)\n",
    "\n",
    "How should the worker divide his time? Calculate the optimal split using the Newton-Raphson method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:25:36.675807Z",
     "iopub.status.busy": "2021-06-22T07:25:36.675369Z",
     "iopub.status.idle": "2021-06-22T07:25:36.696430Z",
     "shell.execute_reply": "2021-06-22T07:25:36.693811Z",
     "shell.execute_reply.started": "2021-06-22T07:25:36.675757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 0 - W = 1.0000 - L = 1.0000 - lam = 1.0000 - f(x_k) = 1.0000 - L(x_k) = [ -0.3333  -0.6667 -22.    ]\n",
      "k = 1 - W = 12.3750 - L = 11.6250 - lam = 0.5000 - f(x_k) = 12.1198 - L(x_k) = [ 0.1529 -0.1525  0.    ]\n",
      "k = 2 - W = 16.4491 - L = 7.5509 - lam = 0.5050 - f(x_k) = 12.6890 - L(x_k) = [0.0093 0.0552 0.    ]\n",
      "k = 3 - W = 16.0133 - L = 7.9867 - lam = 0.5287 - f(x_k) = 12.6992 - L(x_k) = [-0.      0.0013  0.    ]\n",
      "k = 4 - W = 16.0000 - L = 8.0000 - lam = 0.5291 - f(x_k) = 12.6992 - L(x_k) = [-0.  0.  0.]\n",
      "k = 5 - W = 16.0000 - L = 8.0000 - lam = 0.5291 - f(x_k) = 12.6992 - L(x_k) = [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def tru_f(x):\n",
    "    return x[0]**(2/3) * x[1]**(1/3)\n",
    "\n",
    "def f(x):\n",
    "    return np.array([(2 * x[0]**(-1/3) * x[1]**(1/3) / 3) - x[2], (x[0]**(2/3) * x[1]**(-2/3) / 3) - x[2], x[0] + x[1] - 24])\n",
    "\n",
    "#change THIS!\n",
    "def f_jacob(x):\n",
    "    return np.array([[-2 * x[0]**(-4/3) * x[1]**(1/3) / 9, 2 * x[0]**(-1/3) * x[1]**(-2/3) / 9, -1],\n",
    "                     [2 * x[0]**(-1/3) * x[1]**(-2/3) / 9, -2 * x[0]**(2/3) * x[1]**(-5/3) / 9, -1],\n",
    "                     [1, 1, 0]])\n",
    "\n",
    "x_k = np.array([1, 1, 1]) ## Max at (8, 16)\n",
    "\n",
    "for k in range(0, 6):\n",
    "    print(\"k = %d\" %k,\"- W = %.4f\" %x_k[0],\"- L = %.4f\" %x_k[1], \"- lam = %.4f\" %x_k[2],\"- f(x_k) = %.4f\" %tru_f(x_k),\"- L(x_k) =\", f(x_k))\n",
    "    x_k = x_k - np.matmul(np.linalg.inv(f_jacob(x_k)), f(x_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer.\n",
    "\n",
    "\\begin{align}\n",
    "    W^* = 16 \\quad &, \\quad L^* = 8\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "    U(W^*, L^*) &= 12.6992\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## IV. Principal Component Analysis (6 pts.)\n",
    "\n",
    "[`Principal Component Analysis`](https://en.wikipedia.org/wiki/Principal_component_analysis) (PCA) is one of the fundamental techniques for dimensionality reduction and is used in a wide variety of applications in data science, statistics, and machine learning. The basic idea behind PCA is to project the original feature space into a lower dimensional space while retaining a certain level of information. In this case, the amount of information is measured by the variance contained within the dataset.\n",
    "\n",
    "For this section, we will be using the entirety of the diabetes dataset. \n",
    "\n",
    "Your goal is to reduce the dimensionality of the data and learn the relationship between PCA and SVD.\n",
    "\n",
    "For the moment, we will focus on the computational aspects of PCA. You will revisit this topic and discuss its deeper implications in your later classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:25:46.113843Z",
     "iopub.status.busy": "2021-06-22T07:25:46.113395Z",
     "iopub.status.idle": "2021-06-22T07:25:46.133701Z",
     "shell.execute_reply": "2021-06-22T07:25:46.132961Z",
     "shell.execute_reply.started": "2021-06-22T07:25:46.113792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "# Load the diabetes dataset\n",
    "x, y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "# Check shapes of x, y\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1. (1 pts.)\n",
    "\n",
    "Calculate the row-wise mean vector of $x$ and store it in a variable called `x_bar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:25:46.767534Z",
     "iopub.status.busy": "2021-06-22T07:25:46.767096Z",
     "iopub.status.idle": "2021-06-22T07:25:46.775890Z",
     "shell.execute_reply": "2021-06-22T07:25:46.774936Z",
     "shell.execute_reply.started": "2021-06-22T07:25:46.767484Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.,  0., -0.,  0., -0.,  0., -0.,  0., -0., -0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bar = np.mean(x, axis=0)\n",
    "x_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. (1 pts.)\n",
    "\n",
    "Center the data by subtracting $\\bar{x}$ from each column of $x$. Store the result in a variable called `A` which we will refer to as the <i>mean-centered</i> data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:28:14.941661Z",
     "iopub.status.busy": "2021-06-22T07:28:14.941216Z",
     "iopub.status.idle": "2021-06-22T07:28:14.965512Z",
     "shell.execute_reply": "2021-06-22T07:28:14.964723Z",
     "shell.execute_reply.started": "2021-06-22T07:28:14.941610Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018118</td>\n",
       "      <td>0.044485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046879</td>\n",
       "      <td>0.015491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044528</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081414</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
       "\n",
       "            7         8         9  \n",
       "0   -0.002592  0.019908 -0.017646  \n",
       "1   -0.039493 -0.068330 -0.092204  \n",
       "2   -0.002592  0.002864 -0.025930  \n",
       "3    0.034309  0.022692 -0.009362  \n",
       "4   -0.002592 -0.031991 -0.046641  \n",
       "..        ...       ...       ...  \n",
       "437 -0.002592  0.031193  0.007207  \n",
       "438  0.034309 -0.018118  0.044485  \n",
       "439 -0.011080 -0.046879  0.015491  \n",
       "440  0.026560  0.044528 -0.025930  \n",
       "441 -0.039493 -0.004220  0.003064  \n",
       "\n",
       "[442 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = x - x_bar\n",
    "pd.DataFrame(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3. (1 pts.)\n",
    "\n",
    "Calculate the covariance matrix of `A`, which is defined as:\n",
    "\n",
    "\\begin{align*}\n",
    "    C &= A^TA\n",
    "\\end{align*}\n",
    "\n",
    "Store the result in a variable called `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:26:14.980461Z",
     "iopub.status.busy": "2021-06-22T07:26:14.979641Z",
     "iopub.status.idle": "2021-06-22T07:26:15.007327Z",
     "shell.execute_reply": "2021-06-22T07:26:15.006337Z",
     "shell.execute_reply.started": "2021-06-22T07:26:14.980384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.173737</td>\n",
       "      <td>0.185085</td>\n",
       "      <td>0.335427</td>\n",
       "      <td>0.260061</td>\n",
       "      <td>0.219243</td>\n",
       "      <td>-0.075181</td>\n",
       "      <td>0.203841</td>\n",
       "      <td>0.270777</td>\n",
       "      <td>0.301731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.173737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088161</td>\n",
       "      <td>0.241013</td>\n",
       "      <td>0.035277</td>\n",
       "      <td>0.142637</td>\n",
       "      <td>-0.379090</td>\n",
       "      <td>0.332115</td>\n",
       "      <td>0.149918</td>\n",
       "      <td>0.208133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.185085</td>\n",
       "      <td>0.088161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.395415</td>\n",
       "      <td>0.249777</td>\n",
       "      <td>0.261170</td>\n",
       "      <td>-0.366811</td>\n",
       "      <td>0.413807</td>\n",
       "      <td>0.446159</td>\n",
       "      <td>0.388680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.335427</td>\n",
       "      <td>0.241013</td>\n",
       "      <td>0.395415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.242470</td>\n",
       "      <td>0.185558</td>\n",
       "      <td>-0.178761</td>\n",
       "      <td>0.257653</td>\n",
       "      <td>0.393478</td>\n",
       "      <td>0.390429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260061</td>\n",
       "      <td>0.035277</td>\n",
       "      <td>0.249777</td>\n",
       "      <td>0.242470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896663</td>\n",
       "      <td>0.051519</td>\n",
       "      <td>0.542207</td>\n",
       "      <td>0.515501</td>\n",
       "      <td>0.325717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.219243</td>\n",
       "      <td>0.142637</td>\n",
       "      <td>0.261170</td>\n",
       "      <td>0.185558</td>\n",
       "      <td>0.896663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.196455</td>\n",
       "      <td>0.659817</td>\n",
       "      <td>0.318353</td>\n",
       "      <td>0.290600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.075181</td>\n",
       "      <td>-0.379090</td>\n",
       "      <td>-0.366811</td>\n",
       "      <td>-0.178761</td>\n",
       "      <td>0.051519</td>\n",
       "      <td>-0.196455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.738493</td>\n",
       "      <td>-0.398577</td>\n",
       "      <td>-0.273697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.203841</td>\n",
       "      <td>0.332115</td>\n",
       "      <td>0.413807</td>\n",
       "      <td>0.257653</td>\n",
       "      <td>0.542207</td>\n",
       "      <td>0.659817</td>\n",
       "      <td>-0.738493</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.617857</td>\n",
       "      <td>0.417212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.270777</td>\n",
       "      <td>0.149918</td>\n",
       "      <td>0.446159</td>\n",
       "      <td>0.393478</td>\n",
       "      <td>0.515501</td>\n",
       "      <td>0.318353</td>\n",
       "      <td>-0.398577</td>\n",
       "      <td>0.617857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.464670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.301731</td>\n",
       "      <td>0.208133</td>\n",
       "      <td>0.388680</td>\n",
       "      <td>0.390429</td>\n",
       "      <td>0.325717</td>\n",
       "      <td>0.290600</td>\n",
       "      <td>-0.273697</td>\n",
       "      <td>0.417212</td>\n",
       "      <td>0.464670</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.173737  0.185085  0.335427  0.260061  0.219243 -0.075181   \n",
       "1  0.173737  1.000000  0.088161  0.241013  0.035277  0.142637 -0.379090   \n",
       "2  0.185085  0.088161  1.000000  0.395415  0.249777  0.261170 -0.366811   \n",
       "3  0.335427  0.241013  0.395415  1.000000  0.242470  0.185558 -0.178761   \n",
       "4  0.260061  0.035277  0.249777  0.242470  1.000000  0.896663  0.051519   \n",
       "5  0.219243  0.142637  0.261170  0.185558  0.896663  1.000000 -0.196455   \n",
       "6 -0.075181 -0.379090 -0.366811 -0.178761  0.051519 -0.196455  1.000000   \n",
       "7  0.203841  0.332115  0.413807  0.257653  0.542207  0.659817 -0.738493   \n",
       "8  0.270777  0.149918  0.446159  0.393478  0.515501  0.318353 -0.398577   \n",
       "9  0.301731  0.208133  0.388680  0.390429  0.325717  0.290600 -0.273697   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.203841  0.270777  0.301731  \n",
       "1  0.332115  0.149918  0.208133  \n",
       "2  0.413807  0.446159  0.388680  \n",
       "3  0.257653  0.393478  0.390429  \n",
       "4  0.542207  0.515501  0.325717  \n",
       "5  0.659817  0.318353  0.290600  \n",
       "6 -0.738493 -0.398577 -0.273697  \n",
       "7  1.000000  0.617857  0.417212  \n",
       "8  0.617857  1.000000  0.464670  \n",
       "9  0.417212  0.464670  1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = A.T.dot(A)\n",
    "pd.DataFrame(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4. (1 pts.)\n",
    "\n",
    "Calculate the eigenvalues and eigenvectors of the covariance matrix $C$.\n",
    "\n",
    "<u>Sort</u> the pairs and store the eigenvectors in a matrix called `V` and store the <u>square root</u> of the eigenvalues as a diagonal matrix `S`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:26:43.717740Z",
     "iopub.status.busy": "2021-06-22T07:26:43.717348Z",
     "iopub.status.idle": "2021-06-22T07:26:43.724639Z",
     "shell.execute_reply": "2021-06-22T07:26:43.723429Z",
     "shell.execute_reply.started": "2021-06-22T07:26:43.717695Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eig_val, V = np.linalg.eig(C)\n",
    "\n",
    "# Sort\n",
    "sorted_idx = np.argsort(eig_val)[::-1]\n",
    "eig_val = eig_val[sorted_idx]\n",
    "V = V[:, sorted_idx]\n",
    "\n",
    "S = np.diag(np.sqrt(eig_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:26:54.536614Z",
     "iopub.status.busy": "2021-06-22T07:26:54.536176Z",
     "iopub.status.idle": "2021-06-22T07:26:54.559782Z",
     "shell.execute_reply": "2021-06-22T07:26:54.558949Z",
     "shell.execute_reply.started": "2021-06-22T07:26:54.536564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.006044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.221605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.813748</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.77635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.732503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279857</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4        5         6  \\\n",
       "0  2.006044  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "1  0.000000  1.221605  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "2  0.000000  0.000000  1.098163  0.000000  0.000000  0.00000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.977485  0.000000  0.00000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.813748  0.00000  0.000000   \n",
       "5  0.000000  0.000000  0.000000  0.000000  0.000000  0.77635  0.000000   \n",
       "6  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.732503   \n",
       "7  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "8  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "9  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.000000  0.000000  \n",
       "5  0.000000  0.000000  0.000000  \n",
       "6  0.000000  0.000000  0.000000  \n",
       "7  0.658546  0.000000  0.000000  \n",
       "8  0.000000  0.279857  0.000000  \n",
       "9  0.000000  0.000000  0.092523  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:26:59.733374Z",
     "iopub.status.busy": "2021-06-22T07:26:59.732933Z",
     "iopub.status.idle": "2021-06-22T07:26:59.756197Z",
     "shell.execute_reply": "2021-06-22T07:26:59.755393Z",
     "shell.execute_reply.started": "2021-06-22T07:26:59.733324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.216431</td>\n",
       "      <td>-0.044372</td>\n",
       "      <td>-0.494668</td>\n",
       "      <td>0.414009</td>\n",
       "      <td>-0.686864</td>\n",
       "      <td>-0.225851</td>\n",
       "      <td>0.109538</td>\n",
       "      <td>-0.014935</td>\n",
       "      <td>-0.008101</td>\n",
       "      <td>0.003263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.186967</td>\n",
       "      <td>0.386548</td>\n",
       "      <td>0.106858</td>\n",
       "      <td>0.679861</td>\n",
       "      <td>0.373456</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>0.067606</td>\n",
       "      <td>-0.442940</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>0.003661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.303162</td>\n",
       "      <td>0.156281</td>\n",
       "      <td>-0.167532</td>\n",
       "      <td>-0.499825</td>\n",
       "      <td>0.129359</td>\n",
       "      <td>-0.403142</td>\n",
       "      <td>0.519858</td>\n",
       "      <td>-0.392942</td>\n",
       "      <td>-0.042378</td>\n",
       "      <td>0.008248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.271740</td>\n",
       "      <td>0.138256</td>\n",
       "      <td>-0.513568</td>\n",
       "      <td>0.019667</td>\n",
       "      <td>0.486890</td>\n",
       "      <td>-0.272763</td>\n",
       "      <td>-0.320649</td>\n",
       "      <td>0.477364</td>\n",
       "      <td>-0.027194</td>\n",
       "      <td>-0.003221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.343255</td>\n",
       "      <td>-0.573027</td>\n",
       "      <td>0.068587</td>\n",
       "      <td>0.068395</td>\n",
       "      <td>0.129174</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>-0.073649</td>\n",
       "      <td>-0.129414</td>\n",
       "      <td>0.042040</td>\n",
       "      <td>0.709774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.351861</td>\n",
       "      <td>-0.455940</td>\n",
       "      <td>0.269694</td>\n",
       "      <td>0.167774</td>\n",
       "      <td>0.116731</td>\n",
       "      <td>-0.133257</td>\n",
       "      <td>0.230540</td>\n",
       "      <td>0.191311</td>\n",
       "      <td>0.359315</td>\n",
       "      <td>-0.563196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.282436</td>\n",
       "      <td>-0.506243</td>\n",
       "      <td>-0.386028</td>\n",
       "      <td>0.076020</td>\n",
       "      <td>0.244991</td>\n",
       "      <td>0.106372</td>\n",
       "      <td>0.007534</td>\n",
       "      <td>-0.324636</td>\n",
       "      <td>-0.481248</td>\n",
       "      <td>-0.317444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.428833</td>\n",
       "      <td>0.068184</td>\n",
       "      <td>0.380681</td>\n",
       "      <td>-0.007921</td>\n",
       "      <td>-0.143644</td>\n",
       "      <td>-0.033945</td>\n",
       "      <td>-0.071236</td>\n",
       "      <td>0.180588</td>\n",
       "      <td>-0.773817</td>\n",
       "      <td>-0.090595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.378617</td>\n",
       "      <td>0.026189</td>\n",
       "      <td>-0.063632</td>\n",
       "      <td>-0.264427</td>\n",
       "      <td>-0.151661</td>\n",
       "      <td>0.178730</td>\n",
       "      <td>-0.647313</td>\n",
       "      <td>-0.449660</td>\n",
       "      <td>0.189459</td>\n",
       "      <td>-0.264467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.322183</td>\n",
       "      <td>0.084947</td>\n",
       "      <td>-0.276843</td>\n",
       "      <td>-0.087086</td>\n",
       "      <td>0.031388</td>\n",
       "      <td>0.805064</td>\n",
       "      <td>0.357273</td>\n",
       "      <td>0.166609</td>\n",
       "      <td>0.015274</td>\n",
       "      <td>0.002611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.216431 -0.044372 -0.494668  0.414009 -0.686864 -0.225851  0.109538   \n",
       "1 -0.186967  0.386548  0.106858  0.679861  0.373456  0.041731  0.067606   \n",
       "2 -0.303162  0.156281 -0.167532 -0.499825  0.129359 -0.403142  0.519858   \n",
       "3 -0.271740  0.138256 -0.513568  0.019667  0.486890 -0.272763 -0.320649   \n",
       "4 -0.343255 -0.573027  0.068587  0.068395  0.129174  0.005409 -0.073649   \n",
       "5 -0.351861 -0.455940  0.269694  0.167774  0.116731 -0.133257  0.230540   \n",
       "6  0.282436 -0.506243 -0.386028  0.076020  0.244991  0.106372  0.007534   \n",
       "7 -0.428833  0.068184  0.380681 -0.007921 -0.143644 -0.033945 -0.071236   \n",
       "8 -0.378617  0.026189 -0.063632 -0.264427 -0.151661  0.178730 -0.647313   \n",
       "9 -0.322183  0.084947 -0.276843 -0.087086  0.031388  0.805064  0.357273   \n",
       "\n",
       "          7         8         9  \n",
       "0 -0.014935 -0.008101  0.003263  \n",
       "1 -0.442940  0.002106  0.003661  \n",
       "2 -0.392942 -0.042378  0.008248  \n",
       "3  0.477364 -0.027194 -0.003221  \n",
       "4 -0.129414  0.042040  0.709774  \n",
       "5  0.191311  0.359315 -0.563196  \n",
       "6 -0.324636 -0.481248 -0.317444  \n",
       "7  0.180588 -0.773817 -0.090595  \n",
       "8 -0.449660  0.189459 -0.264467  \n",
       "9  0.166609  0.015274  0.002611  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:27:25.295986Z",
     "iopub.status.busy": "2021-06-22T07:27:25.295548Z",
     "iopub.status.idle": "2021-06-22T07:27:25.320613Z",
     "shell.execute_reply": "2021-06-22T07:27:25.319389Z",
     "shell.execute_reply.started": "2021-06-22T07:27:25.295936Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.173737</td>\n",
       "      <td>0.185085</td>\n",
       "      <td>0.335427</td>\n",
       "      <td>0.260061</td>\n",
       "      <td>0.219243</td>\n",
       "      <td>-0.075181</td>\n",
       "      <td>0.203841</td>\n",
       "      <td>0.270777</td>\n",
       "      <td>0.301731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.173737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088161</td>\n",
       "      <td>0.241013</td>\n",
       "      <td>0.035277</td>\n",
       "      <td>0.142637</td>\n",
       "      <td>-0.379090</td>\n",
       "      <td>0.332115</td>\n",
       "      <td>0.149918</td>\n",
       "      <td>0.208133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.185085</td>\n",
       "      <td>0.088161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.395415</td>\n",
       "      <td>0.249777</td>\n",
       "      <td>0.261170</td>\n",
       "      <td>-0.366811</td>\n",
       "      <td>0.413807</td>\n",
       "      <td>0.446159</td>\n",
       "      <td>0.388680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.335427</td>\n",
       "      <td>0.241013</td>\n",
       "      <td>0.395415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.242470</td>\n",
       "      <td>0.185558</td>\n",
       "      <td>-0.178761</td>\n",
       "      <td>0.257653</td>\n",
       "      <td>0.393478</td>\n",
       "      <td>0.390429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260061</td>\n",
       "      <td>0.035277</td>\n",
       "      <td>0.249777</td>\n",
       "      <td>0.242470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896663</td>\n",
       "      <td>0.051519</td>\n",
       "      <td>0.542207</td>\n",
       "      <td>0.515501</td>\n",
       "      <td>0.325717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.219243</td>\n",
       "      <td>0.142637</td>\n",
       "      <td>0.261170</td>\n",
       "      <td>0.185558</td>\n",
       "      <td>0.896663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.196455</td>\n",
       "      <td>0.659817</td>\n",
       "      <td>0.318353</td>\n",
       "      <td>0.290600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.075181</td>\n",
       "      <td>-0.379090</td>\n",
       "      <td>-0.366811</td>\n",
       "      <td>-0.178761</td>\n",
       "      <td>0.051519</td>\n",
       "      <td>-0.196455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.738493</td>\n",
       "      <td>-0.398577</td>\n",
       "      <td>-0.273697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.203841</td>\n",
       "      <td>0.332115</td>\n",
       "      <td>0.413807</td>\n",
       "      <td>0.257653</td>\n",
       "      <td>0.542207</td>\n",
       "      <td>0.659817</td>\n",
       "      <td>-0.738493</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.617857</td>\n",
       "      <td>0.417212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.270777</td>\n",
       "      <td>0.149918</td>\n",
       "      <td>0.446159</td>\n",
       "      <td>0.393478</td>\n",
       "      <td>0.515501</td>\n",
       "      <td>0.318353</td>\n",
       "      <td>-0.398577</td>\n",
       "      <td>0.617857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.464670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.301731</td>\n",
       "      <td>0.208133</td>\n",
       "      <td>0.388680</td>\n",
       "      <td>0.390429</td>\n",
       "      <td>0.325717</td>\n",
       "      <td>0.290600</td>\n",
       "      <td>-0.273697</td>\n",
       "      <td>0.417212</td>\n",
       "      <td>0.464670</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.173737  0.185085  0.335427  0.260061  0.219243 -0.075181   \n",
       "1  0.173737  1.000000  0.088161  0.241013  0.035277  0.142637 -0.379090   \n",
       "2  0.185085  0.088161  1.000000  0.395415  0.249777  0.261170 -0.366811   \n",
       "3  0.335427  0.241013  0.395415  1.000000  0.242470  0.185558 -0.178761   \n",
       "4  0.260061  0.035277  0.249777  0.242470  1.000000  0.896663  0.051519   \n",
       "5  0.219243  0.142637  0.261170  0.185558  0.896663  1.000000 -0.196455   \n",
       "6 -0.075181 -0.379090 -0.366811 -0.178761  0.051519 -0.196455  1.000000   \n",
       "7  0.203841  0.332115  0.413807  0.257653  0.542207  0.659817 -0.738493   \n",
       "8  0.270777  0.149918  0.446159  0.393478  0.515501  0.318353 -0.398577   \n",
       "9  0.301731  0.208133  0.388680  0.390429  0.325717  0.290600 -0.273697   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.203841  0.270777  0.301731  \n",
       "1  0.332115  0.149918  0.208133  \n",
       "2  0.413807  0.446159  0.388680  \n",
       "3  0.257653  0.393478  0.390429  \n",
       "4  0.542207  0.515501  0.325717  \n",
       "5  0.659817  0.318353  0.290600  \n",
       "6 -0.738493 -0.398577 -0.273697  \n",
       "7  1.000000  0.617857  0.417212  \n",
       "8  0.617857  1.000000  0.464670  \n",
       "9  0.417212  0.464670  1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(V.dot(S**2).dot(V.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interlude\n",
    "\n",
    "In the following expression:\n",
    "\n",
    "\\begin{align*}\n",
    "    T &= AV\n",
    "\\end{align*}\n",
    "\n",
    "the columns of the matrix $T$ are called the <b>principal components</b> and columns of $V$ (the eigenvectors of $C = A^TA$) are called the <b>loadings</b>.\n",
    "\n",
    "Notice that if we had directly calculated the SVD of the mean-centered data $A$, we would get the decomposition:\n",
    "\n",
    "\\begin{align*}\n",
    "    A &= U \\Sigma V^T\n",
    "\\end{align*}\n",
    "\n",
    "The principal components are therefore given by:\n",
    "\n",
    "\\begin{align*}\n",
    "    T &= AV \\\\\n",
    "    &= U \\Sigma V^T V\\\\\n",
    "    &= U \\Sigma\n",
    "\\end{align*}\n",
    "\n",
    "The singular values $\\sigma_i$ in $\\Sigma$ (corresponding to `S` in your code above) measure the amount of variance in the dataset that is captured by the principal components in $T$. Similar to the concept of \"compression\" discussed in the SVD seatwork, we can now decide how much information to retain by deciding on <u>how many of the principal components we wish to keep</u> (note that we select the top $k$ principal components instead of the top $k$ singular values). In essence, we have decomposed our mean-cetered data $A$ into its directions of maximal variance. \n",
    "\n",
    "Thus, we have now established a statistical interpretation of SVD through the variances and covariances of our data! Very cool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5. (1 pts.)\n",
    "\n",
    "Calculate the matrix of principal components $T$. Store the result in a variable called `T`.\n",
    "\n",
    "Print the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:27:55.608800Z",
     "iopub.status.busy": "2021-06-22T07:27:55.608317Z",
     "iopub.status.idle": "2021-06-22T07:27:55.635980Z",
     "shell.execute_reply": "2021-06-22T07:27:55.635221Z",
     "shell.execute_reply.started": "2021-06-22T07:27:55.608748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.027931</td>\n",
       "      <td>0.092601</td>\n",
       "      <td>-0.028027</td>\n",
       "      <td>0.003939</td>\n",
       "      <td>-0.012207</td>\n",
       "      <td>-0.048099</td>\n",
       "      <td>0.008553</td>\n",
       "      <td>-0.036028</td>\n",
       "      <td>0.008613</td>\n",
       "      <td>-0.002329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.134686</td>\n",
       "      <td>-0.065263</td>\n",
       "      <td>-0.001328</td>\n",
       "      <td>0.022356</td>\n",
       "      <td>-0.006813</td>\n",
       "      <td>-0.048184</td>\n",
       "      <td>-0.010674</td>\n",
       "      <td>0.008962</td>\n",
       "      <td>-0.024026</td>\n",
       "      <td>0.002073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.012945</td>\n",
       "      <td>0.077764</td>\n",
       "      <td>-0.035164</td>\n",
       "      <td>0.037647</td>\n",
       "      <td>-0.055357</td>\n",
       "      <td>-0.052931</td>\n",
       "      <td>0.021994</td>\n",
       "      <td>-0.040109</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>-0.002577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002345</td>\n",
       "      <td>-0.018182</td>\n",
       "      <td>0.095750</td>\n",
       "      <td>-0.065318</td>\n",
       "      <td>0.012154</td>\n",
       "      <td>0.021181</td>\n",
       "      <td>-0.022933</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>0.006558</td>\n",
       "      <td>-0.003548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035981</td>\n",
       "      <td>-0.038621</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>-0.006343</td>\n",
       "      <td>-0.038746</td>\n",
       "      <td>-0.020760</td>\n",
       "      <td>0.050409</td>\n",
       "      <td>-0.002107</td>\n",
       "      <td>-0.000518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>-0.058958</td>\n",
       "      <td>0.049275</td>\n",
       "      <td>-0.044173</td>\n",
       "      <td>0.031215</td>\n",
       "      <td>0.009718</td>\n",
       "      <td>-0.022801</td>\n",
       "      <td>-0.018761</td>\n",
       "      <td>-0.006016</td>\n",
       "      <td>0.017975</td>\n",
       "      <td>-0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.060155</td>\n",
       "      <td>-0.036211</td>\n",
       "      <td>0.083249</td>\n",
       "      <td>0.053914</td>\n",
       "      <td>-0.004472</td>\n",
       "      <td>0.046301</td>\n",
       "      <td>0.055821</td>\n",
       "      <td>-0.008583</td>\n",
       "      <td>0.017682</td>\n",
       "      <td>0.001592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.009763</td>\n",
       "      <td>0.057337</td>\n",
       "      <td>-0.023596</td>\n",
       "      <td>0.064372</td>\n",
       "      <td>-0.006739</td>\n",
       "      <td>-0.002154</td>\n",
       "      <td>0.030225</td>\n",
       "      <td>0.023387</td>\n",
       "      <td>0.005386</td>\n",
       "      <td>0.002800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.032956</td>\n",
       "      <td>-0.009994</td>\n",
       "      <td>0.041321</td>\n",
       "      <td>-0.076903</td>\n",
       "      <td>0.005691</td>\n",
       "      <td>-0.026489</td>\n",
       "      <td>-0.025956</td>\n",
       "      <td>-0.003742</td>\n",
       "      <td>0.006051</td>\n",
       "      <td>-0.002166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0.090561</td>\n",
       "      <td>-0.189108</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.010493</td>\n",
       "      <td>0.028531</td>\n",
       "      <td>0.078345</td>\n",
       "      <td>-0.011666</td>\n",
       "      <td>-0.056383</td>\n",
       "      <td>-0.034745</td>\n",
       "      <td>-0.007352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0   -0.027931  0.092601 -0.028027  0.003939 -0.012207 -0.048099  0.008553   \n",
       "1    0.134686 -0.065263 -0.001328  0.022356 -0.006813 -0.048184 -0.010674   \n",
       "2   -0.012945  0.077764 -0.035164  0.037647 -0.055357 -0.052931  0.021994   \n",
       "3   -0.002345 -0.018182  0.095750 -0.065318  0.012154  0.021181 -0.022933   \n",
       "4    0.035981 -0.038621  0.002724  0.006541 -0.006343 -0.038746 -0.020760   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437 -0.058958  0.049275 -0.044173  0.031215  0.009718 -0.022801 -0.018761   \n",
       "438 -0.060155 -0.036211  0.083249  0.053914 -0.004472  0.046301  0.055821   \n",
       "439  0.009763  0.057337 -0.023596  0.064372 -0.006739 -0.002154  0.030225   \n",
       "440 -0.032956 -0.009994  0.041321 -0.076903  0.005691 -0.026489 -0.025956   \n",
       "441  0.090561 -0.189108  0.002301  0.010493  0.028531  0.078345 -0.011666   \n",
       "\n",
       "            7         8         9  \n",
       "0   -0.036028  0.008613 -0.002329  \n",
       "1    0.008962 -0.024026  0.002073  \n",
       "2   -0.040109  0.001206 -0.002577  \n",
       "3    0.017496  0.006558 -0.003548  \n",
       "4    0.050409 -0.002107 -0.000518  \n",
       "..        ...       ...       ...  \n",
       "437 -0.006016  0.017975 -0.001200  \n",
       "438 -0.008583  0.017682  0.001592  \n",
       "439  0.023387  0.005386  0.002800  \n",
       "440 -0.003742  0.006051 -0.002166  \n",
       "441 -0.056383 -0.034745 -0.007352  \n",
       "\n",
       "[442 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = A.dot(V)\n",
    "pd.DataFrame(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6. (1 pts.)\n",
    "\n",
    "Select the 1st principal component. This will be our new feature $x'$.\n",
    "\n",
    "Fit a simple linear regression to this \"new\" dataset:\n",
    "\n",
    "\\begin{align*}\n",
    "    y = \\theta_0 + \\theta_1 x'\n",
    "\\end{align*}\n",
    "\n",
    "Find the true (i.e. <u>stable</u> and <u>exact</u>) parameter estimates $\\hat{\\theta_0}, \\hat{\\theta_1}$ using your SGD implementation in Part I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:29:04.856051Z",
     "iopub.status.busy": "2021-06-22T07:29:04.855594Z",
     "iopub.status.idle": "2021-06-22T07:29:04.862058Z",
     "shell.execute_reply": "2021-06-22T07:29:04.860942Z",
     "shell.execute_reply.started": "2021-06-22T07:29:04.855998Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_new = T[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T07:52:13.970225Z",
     "iopub.status.busy": "2021-06-22T07:52:13.969676Z",
     "iopub.status.idle": "2021-06-22T07:52:14.541506Z",
     "shell.execute_reply": "2021-06-22T07:52:14.540342Z",
     "shell.execute_reply.started": "2021-06-22T07:52:13.970148Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 0 -- e = 0.5000 -- theta_k[0] = 1.0000 -- theta_k[1] = 1.0000 -- J(theta_k) = 28779.3853\n",
      "k = 1 -- e = 0.4999 -- theta_k[0] = 152.1335 -- theta_k[1] = -3.0897 -- J(theta_k) = 5904.7559\n",
      "k = 2 -- e = 0.4998 -- theta_k[0] = 152.1335 -- theta_k[1] = -7.1415 -- J(theta_k) = 5872.0655\n",
      "k = 3 -- e = 0.4998 -- theta_k[0] = 152.1335 -- theta_k[1] = -11.1558 -- J(theta_k) = 5839.9727\n",
      "k = 4 -- e = 0.4997 -- theta_k[0] = 152.1335 -- theta_k[1] = -15.1329 -- J(theta_k) = 5808.4666\n",
      "k = 100 -- e = 0.4918 -- theta_k[0] = 152.1335 -- theta_k[1] = -266.8756 -- J(theta_k) = 4400.3016\n",
      "k = 200 -- e = 0.4837 -- theta_k[0] = 152.1335 -- theta_k[1] = -373.8981 -- J(theta_k) = 4151.2312\n",
      "k = 300 -- e = 0.4755 -- theta_k[0] = 152.1335 -- theta_k[1] = -417.2911 -- J(theta_k) = 4109.6692\n",
      "k = 400 -- e = 0.4673 -- theta_k[0] = 152.1335 -- theta_k[1] = -435.1461 -- J(theta_k) = 4102.5242\n",
      "k = 500 -- e = 0.4592 -- theta_k[0] = 152.1335 -- theta_k[1] = -442.6020 -- J(theta_k) = 4101.2588\n",
      "k = 600 -- e = 0.4510 -- theta_k[0] = 152.1335 -- theta_k[1] = -445.7614 -- J(theta_k) = 4101.0279\n",
      "k = 700 -- e = 0.4428 -- theta_k[0] = 152.1335 -- theta_k[1] = -447.1201 -- J(theta_k) = 4100.9845\n",
      "k = 800 -- e = 0.4347 -- theta_k[0] = 152.1335 -- theta_k[1] = -447.7130 -- J(theta_k) = 4100.9761\n",
      "k = 900 -- e = 0.4265 -- theta_k[0] = 152.1335 -- theta_k[1] = -447.9756 -- J(theta_k) = 4100.9744\n",
      "k = 1000 -- e = 0.4183 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.0935 -- J(theta_k) = 4100.9741\n",
      "k = 1100 -- e = 0.4102 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.1473 -- J(theta_k) = 4100.9740\n",
      "k = 1200 -- e = 0.4020 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.1722 -- J(theta_k) = 4100.9740\n",
      "k = 1300 -- e = 0.3938 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.1839 -- J(theta_k) = 4100.9740\n",
      "k = 1400 -- e = 0.3857 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.1895 -- J(theta_k) = 4100.9740\n",
      "k = 1500 -- e = 0.3775 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.1922 -- J(theta_k) = 4100.9740\n",
      "k = 1600 -- e = 0.3693 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.1935 -- J(theta_k) = 4100.9740\n",
      "k = 1700 -- e = 0.3612 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.1942 -- J(theta_k) = 4100.9740\n",
      "k = 1800 -- e = 0.3530 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.1945 -- J(theta_k) = 4100.9740\n",
      "k = 1900 -- e = 0.3448 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.1947 -- J(theta_k) = 4100.9740\n",
      "k = 2000 -- e = 0.3367 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.1948 -- J(theta_k) = 4100.9740\n",
      "k = 2100 -- e = 0.3285 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.1948 -- J(theta_k) = 4100.9740\n",
      "k = 2200 -- e = 0.3203 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.1948 -- J(theta_k) = 4100.9740\n",
      "k = 2300 -- e = 0.3122 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.1948 -- J(theta_k) = 4100.9740\n",
      "k = 2400 -- e = 0.3040 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.1948 -- J(theta_k) = 4100.9740\n",
      "k = 2500 -- e = 0.2958 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.1949 -- J(theta_k) = 4100.9740\n",
      "k = 2600 -- e = 0.2877 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.1949 -- J(theta_k) = 4100.9740\n",
      "k = 2700 -- e = 0.2795 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.1949 -- J(theta_k) = 4100.9740\n",
      "k = 2800 -- e = 0.2713 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.1949 -- J(theta_k) = 4100.9740\n",
      "k = 2900 -- e = 0.2632 -- theta_k[0] = 152.1335 -- theta_k[1] = -448.1949 -- J(theta_k) = 4100.9740\n"
     ]
    }
   ],
   "source": [
    "# Set m = 442 so you can see the answer\n",
    "m = 442\n",
    "tau = 6000\n",
    "learning_rate_0 = 0.5\n",
    "learning_rate_tau = 0.01\n",
    "theta_k = np.array([1, 1])\n",
    "\n",
    "# Your code here\n",
    "\n",
    "def sample_minibatch(x, y, m):\n",
    "    random_idx = np.random.choice(range(x.shape[0]), size=m, replace=False)\n",
    "    return x[random_idx], y[random_idx]\n",
    "\n",
    "def J(theta, x, y):\n",
    "    return np.mean((y - (theta[0] + theta[1]*x))**2)\n",
    "\n",
    "for k in range(0, 3000):\n",
    "    \n",
    "    ### Adjust learning rate\n",
    "    if k <= tau:\n",
    "        alpha = k/tau\n",
    "        learning_rate = (1-alpha)*learning_rate_0 + alpha*learning_rate_tau\n",
    "    \n",
    "    ### Diagnostics\n",
    "    if k < 5:\n",
    "        print(\"k = %d --\" %k,\"e = %.4f --\" %learning_rate,\"theta_k[0] = %.4f --\" %theta_k[0],\"theta_k[1] = %.4f --\" %theta_k[1], \"J(theta_k) = %.4f\" %J(theta_k, x_new, y))\n",
    "    elif k % 100 == 0:\n",
    "        print(\"k = %d --\" %k,\"e = %.4f --\" %learning_rate,\"theta_k[0] = %.4f --\" %theta_k[0],\"theta_k[1] = %.4f --\" %theta_k[1], \"J(theta_k) = %.4f\" %J(theta_k, x_new, y))\n",
    "    #else:\n",
    "    #    break\n",
    "    \n",
    "    ### Sample minibatch\n",
    "    x_mini, y_mini = sample_minibatch(x_new, y, m)\n",
    "    \n",
    "    ### Gradient update\n",
    "    theta_k = theta_k - learning_rate*np.array([np.mean(-2*y_mini + 2*theta_k[0] + 2*theta_k[1]*x_mini), np.mean(-2*y_mini*x_mini + 2*theta_k[0]*x_mini + 2*theta_k[1]*x_mini**2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
