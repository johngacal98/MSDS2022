{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d7fb44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T07:37:10.518109Z",
     "start_time": "2021-07-22T07:37:09.766214Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf60cda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T07:38:02.657258Z",
     "start_time": "2021-07-22T07:38:02.634331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bernoulli likelihood\n",
    "np.random.seed(1)\n",
    "\n",
    "#generate bern samples\n",
    "\n",
    "x = np.random.binomial(n=1, p=0.75, size=100)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a107a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T07:38:07.778485Z",
     "start_time": "2021-07-22T07:38:07.770790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3c76b1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T07:40:23.907959Z",
     "start_time": "2021-07-22T07:40:23.894831Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-7107f11dbf31>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).type(torch.FloatTensor)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
       "        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "        1., 0., 1., 1., 1., 1., 0., 1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(x).type(torch.FloatTensor)\n",
    "x.requires_grad = True \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b914ad9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T07:43:07.057714Z",
     "start_time": "2021-07-22T07:43:07.051966Z"
    }
   },
   "outputs": [],
   "source": [
    "def neg_loglik_bernoulli(x, p):\n",
    "    \"\"\"\n",
    "    x,p should be torch tensors\n",
    "    \"\"\"\n",
    "    return -torch.sum(torch.log(x*p + (1-x)*(1-p))) #logging the pmf of bern and sum then negative because we are maximizing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4986a1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T07:51:16.542210Z",
     "start_time": "2021-07-22T07:51:16.371355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p =  [0.5596386]\n",
      "neg-loglik =  63.56 p = [0.56] dL/dp = [-85.359]\n",
      "neg-loglik =  53.93 p = [0.77] dL/dp = [-0.6065]\n",
      "neg-loglik =  53.93 p = [0.77] dL/dp = [-0.0018]\n",
      "neg-loglik =  53.93 p = [0.77] dL/dp = [-0.0003]\n",
      "neg-loglik =  53.93 p = [0.77] dL/dp = [-0.0003]\n"
     ]
    }
   ],
   "source": [
    "#initialize guess for p to use grad descent\n",
    "torch.manual_seed(4)\n",
    "p = torch.rand(1, requires_grad=True)\n",
    "print('p = ', p.data.numpy())\n",
    "\n",
    "#grad descent, minimize negative loglikelihood\n",
    "learning_rate = 0.0001\n",
    "\n",
    "\n",
    "#training loop\n",
    "for t in range(500):\n",
    "    neg_loglik = neg_loglik_bernoulli(x, p) #forward pass\n",
    "    neg_loglik.backward() #calculates the gradients\n",
    "    \n",
    "    if t%100 == 0:\n",
    "        print('neg-loglik = ', neg_loglik.data.numpy().round(2), 'p =', p.data.numpy().round(2), 'dL/dp =', p.grad.data.numpy().round(4))\n",
    "        \n",
    "    #actual gradient desc\n",
    "    p.data -= learning_rate*p.grad.data\n",
    "    p.grad.data.zero_() #resets gradients for each epoch\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e980339",
   "metadata": {},
   "source": [
    "### Exponential Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72f1458d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T07:54:23.608585Z",
     "start_time": "2021-07-22T07:54:23.599069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0000, 1.5000, 2.1000], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [3, 1.5, 2.1] #from lecture slides\n",
    "x = torch.tensor(x).type(torch.FloatTensor)\n",
    "x.requires_grad = True\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b42783b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T07:55:36.362387Z",
     "start_time": "2021-07-22T07:55:36.357593Z"
    }
   },
   "outputs": [],
   "source": [
    "def neg_loglik_exponential(x, beta):\n",
    "    return -torch.sum(torch.log(beta*torch.exp(-x*beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9565a242",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T08:04:15.964600Z",
     "start_time": "2021-07-22T08:04:15.678602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta = [0.8302519]\n",
      "neg-loglik =  6.04 beta = [0.8303] dL/dp = [2.9866]\n",
      "neg-loglik =  5.37 beta = [0.4545] dL/dp = [0.]\n",
      "neg-loglik =  5.37 beta = [0.4545] dL/dp = [0.]\n",
      "neg-loglik =  5.37 beta = [0.4545] dL/dp = [0.]\n",
      "neg-loglik =  5.37 beta = [0.4545] dL/dp = [0.]\n",
      "neg-loglik =  5.37 beta = [0.4545] dL/dp = [0.]\n",
      "neg-loglik =  5.37 beta = [0.4545] dL/dp = [0.]\n",
      "neg-loglik =  5.37 beta = [0.4545] dL/dp = [0.]\n",
      "neg-loglik =  5.37 beta = [0.4545] dL/dp = [0.]\n",
      "neg-loglik =  5.37 beta = [0.4545] dL/dp = [0.]\n"
     ]
    }
   ],
   "source": [
    "#initialize random guess for beta\n",
    "torch.manual_seed(5)\n",
    "beta = torch.rand(1, requires_grad=True)\n",
    "print('beta =', beta.data.numpy())\n",
    "\n",
    "#grad desc, minimize negative loglikelihood\n",
    "\n",
    "learning_rate = 0.01\n",
    "for t in range(1000):\n",
    "    \n",
    "    neg_loglik = neg_loglik_exponential(x, beta)\n",
    "    neg_loglik.backward() #backward pass -> calc the gradient dL/dbeta\n",
    "    \n",
    "    if t%100 == 0:\n",
    "        print('neg-loglik = ', neg_loglik.data.numpy().round(2), 'beta =', beta.data.numpy().round(4), 'dL/dp =', beta.grad.data.numpy().round(4))\n",
    "    \n",
    "    beta.data -= learning_rate * beta.grad.data\n",
    "    beta.grad.data.zero_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
