{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T23:16:52.397998Z",
     "start_time": "2021-05-14T23:16:52.394752Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef26d7a41c48a91dfde846da097059d9",
     "grade": false,
     "grade_id": "cell-db62df71983afb39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.testing import assert_equal, assert_array_equal, assert_allclose\n",
    "from pandas.testing import assert_series_equal, assert_frame_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8fe9ad5fb6472bd9a46f597c9d8f073f",
     "grade": false,
     "grade_id": "cell-294c365e70212058",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problem 1\n",
    "Create a function `init_series` that will return the `pandas.Series` `s1`, `s2` and `s3` shown below. Create another function `init_df` that takes in `s1` and `s2` and returns `df1` and `df2` below.\n",
    "\n",
    "<img src=\"series.png\" style=\"width: 15em; display: inline\" /> <img src=\"df.png\" style=\"width: 10em; display: inline\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T13:48:23.536485Z",
     "start_time": "2021-05-14T13:48:23.527652Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0b783a48baeda4823ecd49099a0f38c",
     "grade": false,
     "grade_id": "cell-158226359b66bc25",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def init_series():\n",
    "    '''reads the data from /mnt/data/public/retaildata/Online Retail.csv and \n",
    "    returns the sum of the first 5 rows with the corresponding row of the last\n",
    "    5 rows for columns Quantity and UnitPrice as a numpy array.\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    s1, s2, s3: pandas Series \n",
    "        \n",
    "    \n",
    "    '''\n",
    "    s1 = pd.Series(np.arange(1,101,11, dtype = 'float64'), index=list('abcdefghij'), name ='foo')\n",
    "    s2 = pd.Series(np.arange(0,10, dtype = 'int64'), index=list('fghijklmno'))\n",
    "    s3 = pd.Series([5]*3, index=list('xyz'), dtype = 'int64')\n",
    "    return s1, s2, s3\n",
    "\n",
    "\n",
    "def init_df(s1, s2):\n",
    "    '''reads the data from /mnt/data/public/retaildata/Online Retail.csv and \n",
    "    returns the sum of the first 5 rows with the corresponding row of the last\n",
    "    5 rows for columns Quantity and UnitPrice as a numpy array.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    s1: pandas Series\n",
    "        pandas Series from init_series function\n",
    "        \n",
    "    s2: pandas Series \n",
    "        pandas Series from init_series function\n",
    "        \n",
    "    Returns\n",
    "    -------------\n",
    "    df1: pandas DataFrame\n",
    "    \n",
    "    df2: pandas DataFrame\n",
    "    \n",
    "    '''\n",
    "    df1 = pd.DataFrame(s1)\n",
    "    df2 = pd.concat([s2,s1], axis = 1, sort = True)\n",
    "    df2.columns = ['Series2', 'Series1']\n",
    "    \n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T23:14:16.696281Z",
     "start_time": "2021-05-14T23:14:16.669318Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab8edf5f4012a81e8ea30daa38d3058a",
     "grade": true,
     "grade_id": "cell-1b2e17298e01d7c8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "s1, s2, s3 = init_series()\n",
    "df1, df2 = init_df(s1, s2)\n",
    "assert_equal(isinstance(s1, pd.Series), True)\n",
    "assert_equal(isinstance(s2, pd.Series), True)\n",
    "assert_equal(isinstance(s3, pd.Series), True)\n",
    "assert_equal(isinstance(df1, pd.DataFrame), True)\n",
    "assert_equal(isinstance(df2, pd.DataFrame), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "53c00e4d5720611f09b4cdf777021d66",
     "grade": false,
     "grade_id": "cell-7a4702b71a2bec4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problem 2\n",
    "Create a function `top_plus_bottom` that reads the data from `/mnt/data/public/retaildata/Online Retail.csv` and returns the sum of the first 5 rows with the corresponding row of the last 5 rows for columns `Quantity` and `UnitPrice` as a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T23:14:21.687130Z",
     "start_time": "2021-05-14T23:14:21.681884Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfaa9c313fa5eefde929322a1bb37343",
     "grade": false,
     "grade_id": "cell-3d02db6977bf91fe",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def top_plus_bottom():\n",
    "    '''reads the data from /mnt/data/public/retaildata/Online Retail.csv and \n",
    "    returns the sum of the first 5 rows with the corresponding row of the last\n",
    "    5 rows for columns Quantity and UnitPrice as a numpy array.\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    sum_arr: numpy array \n",
    "        sum of the first 5 rows with the corresponding row of the last 5 rows \n",
    "        for columns Quantity and UnitPrice\n",
    "    \n",
    "    '''\n",
    "    df = pd.read_csv('/mnt/data/public/retaildata/Online Retail.csv')\n",
    "    s_head = df[['Quantity','UnitPrice']].head()\n",
    "    s_tail = df[['Quantity','UnitPrice']].tail()\n",
    "    sum_arr = np.array(s_head) + np.array(s_tail)\n",
    "    return sum_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T23:14:33.989297Z",
     "start_time": "2021-05-14T23:14:33.284878Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "378c33fe069ce2f35089863120ce755f",
     "grade": true,
     "grade_id": "cell-1f1115cf5ece4d04",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tb_sum = top_plus_bottom()\n",
    "assert_equal(isinstance(tb_sum, np.ndarray), True)\n",
    "assert_equal(tb_sum.shape, (5, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1dd122cec702091bf69402f7c28ad507",
     "grade": false,
     "grade_id": "cell-d4c5f4d01c0bac83",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problem 3\n",
    "Create a function `count_alone` that reads `/mnt/data/public/elections/comelec/voters_profile/philippine_2016_voter_profile_by_age_group.csv` and returns a `pandas` `DataFrame` with an additional column `alone` that is equal to the sum of the `single`, `widow` and `legally_seperated` (sic) columns. The dataframe should be sorted in decreasing order based on `alone`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T23:16:08.405117Z",
     "start_time": "2021-05-14T23:16:08.400972Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c753ba0e189c813c9ce4bb7254d9ffbe",
     "grade": false,
     "grade_id": "cell-f81cb2a1976b0ebd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2988048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7427782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5914888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3797520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2435669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1454999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>968219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>675589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>524783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>427863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>960649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27576009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       alone\n",
       "0    2988048\n",
       "1    7427782\n",
       "2    5914888\n",
       "3    3797520\n",
       "4    2435669\n",
       "5    1454999\n",
       "6     968219\n",
       "7     675589\n",
       "8     524783\n",
       "9     427863\n",
       "10    960649\n",
       "11  27576009"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_alone():\n",
    "    '''reads /mnt/data/public/elections/comelec/voters_profile/\n",
    "    philippine_2016_voter_profile_by_age_group.csv and returns a pandas \n",
    "    DataFrame with an additional column alone that is equal to the sum of the \n",
    "    single, widow and legally_seperated (sic) columns. The dataframe is sorted\n",
    "    in decreasing order based on alone.\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    output: pandas DataFrame \n",
    "        DataFrame with an additional column alone that is equal to the sum of \n",
    "        the single, widow and legally_seperated (sic) columns. The dataframe \n",
    "        is sorted in decreasing order based on alone.\n",
    "    \n",
    "    '''\n",
    "    df3 = pd.read_csv('/mnt/data/public/elections/comelec/voters_profile' +\n",
    "    '/philippine_2016_voter_profile_by_age_group.csv')\n",
    "\n",
    "    SWL = df3[['single','widow','legally_seperated']].head()\n",
    "    sum_SWL = 0\n",
    "    for i in SWL:\n",
    "        sum_SWL = sum_SWL + df3[i]\n",
    "\n",
    "#   sum_SWL = df3['single'] + df3['widow'] + df3['legally_seperated']\n",
    "#   commented line of code is alternative \n",
    "\n",
    "    df3['alone'] = sum_SWL\n",
    "    return df3\n",
    "\n",
    "count_alone()[['alone']] #check values if correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T23:17:04.086180Z",
     "start_time": "2021-05-14T23:17:04.070197Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44f25dad5161790a648029c65a779183",
     "grade": true,
     "grade_id": "cell-572a8db601e19ad2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df_alone = count_alone()\n",
    "assert_array_equal(\n",
    "    df_alone.columns,\n",
    "    ['age_group', 'registered_voter', 'male', 'female', 'literacy',\n",
    "     'indigenous_people', 'person_with_disability', 'single', 'married',\n",
    "     'widow', 'legally_seperated', 'alone'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d45bd648462ccec60ad7b7185283e89",
     "grade": false,
     "grade_id": "cell-42fa2f2b41391f10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problem 4\n",
    "Create a function `scores_stats` that reads `/mnt/data/public/movielens/20m/ml-20m/genome-scores.csv` and returns a `pandas` `Series` that contains the count, mean, standard deviation and quartiles of the `relevance` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T23:17:31.991106Z",
     "start_time": "2021-05-14T23:17:31.986169Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b81b7e7ac26e868ae02b94f6b989ab0d",
     "grade": false,
     "grade_id": "cell-639d85e7be4418f0",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def scores_stats():\n",
    "    '''reads /mnt/data/public/movielens/20m/ml-20m/genome-scores.csv and \n",
    "    returns a pandas Series that contains the count, mean, standard deviation \n",
    "    and quartiles of the relevance column. \n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    output: pandas Series \n",
    "        It contains the count, mean, standard deviation and quartiles of the \n",
    "        relevance column.\n",
    "    \n",
    "    '''\n",
    "    df4 = pd.read_csv('/mnt/data/public/movielens/20m'\n",
    "                      +'/ml-20m/genome-scores.csv')\n",
    "    S_rel = df4['relevance']\n",
    "    S_quan = S_rel.quantile([0.25,0.5,0.75])\n",
    "\n",
    "    output = pd.Series([S_rel.count(),np.mean(S_rel),np.std(S_rel),\\\n",
    "                        np.min(S_rel)])\n",
    "    output = output.append(S_quan)\n",
    "    output = output.append(pd.Series([np.max(S_rel)]))\n",
    "    output.index = ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T23:17:56.245164Z",
     "start_time": "2021-05-14T23:17:53.289350Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af15fd4e3c152664cdaa61d7a4d87c98",
     "grade": true,
     "grade_id": "cell-ad40c0775b40a5cf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "stats = scores_stats()\n",
    "assert_equal(isinstance(stats, pd.Series), True)\n",
    "assert_array_equal(\n",
    "    stats.index, ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f60755a4990ba04c10ff919efc98bb1",
     "grade": false,
     "grade_id": "cell-3e10e3490f1f0996",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problem 5\n",
    "Write a function `top_cat` that reads `/mnt/data/public/agora/Agora.csv` and returns a `pandas` `Series` that contains the top 10 most popular categories along with their counts, sorted from most popular to least popular. The index of the series should be the name of the category and the value is the corresponding count. The file follows `latin1` encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T23:18:58.031911Z",
     "start_time": "2021-05-14T23:18:58.025659Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0cb60983bc472c9a0711b95690e54056",
     "grade": false,
     "grade_id": "cell-fca389a5a91ff02b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def top_cat():\n",
    "    '''reads /mnt/data/public/agora/Agora.csv and returns a pandas Series that \n",
    "    contains the top 10 most popular categories along with their counts, \n",
    "    sorted from most popular to least popular. The index of the series is \n",
    "    the name of the category and the value is the corresponding count. \n",
    "    The file follows latin1 encoding. \n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    output: pandas DataFrame \n",
    "        DataFrame that contains the top 10 most popular categories along with \n",
    "        their counts, sorted from most popular to least popular. The index of \n",
    "        the series is the name of the category and the value is the \n",
    "        corresponding count. The file follows latin1 encoding. \n",
    "    \n",
    "    '''\n",
    "    df5 = pd.read_csv('/mnt/data/public/agora/Agora.csv', encoding = 'latin_1')\n",
    "    output = df5[' Category'].value_counts().head(10)\n",
    "    return output\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T23:19:11.548216Z",
     "start_time": "2021-05-14T23:19:10.963214Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8643d3d113c69d493eac4f2b343740dd",
     "grade": true,
     "grade_id": "cell-84e1fabec2e4d25b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "top_cats = top_cat()\n",
    "assert_equal(isinstance(top_cats, pd.core.series.Series), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cdf3be6b66c724f8887ff6da3051a71b",
     "grade": false,
     "grade_id": "cell-75be9fe50ab3f931",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problem 6\n",
    "Create a function `listing_info` that reads `/mnt/data/public/insideairbnb/data.insideairbnb.com/united-kingdom/england/london/2015-04-06/data/listings.csv.gz` and returns a `pandas` `DataFrame`.  The index of the data frame should be the `id` with the rows sorted by increasing order of `id`. The columns are `name`, `summary`, `space` and `description`. Include only rows for IDs from 11076 to 15400 (inclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T23:19:29.839124Z",
     "start_time": "2021-05-14T23:19:29.833533Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "331ebc518a45ee9da212f0b5c378a830",
     "grade": false,
     "grade_id": "cell-6cb6fee8ace3efcd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def listing_info():\n",
    "    '''reads /mnt/data/public/insideairbnb/data.insideairbnb.com/\n",
    "    united-kingdom/england/london/2015-04-06/data/listings.csv.gz and returns \n",
    "    a pandas DataFrame. The index of the data frame should be the id with the \n",
    "    rows sorted by increasing order of id. The columns are name, summary, \n",
    "    space and description. Include rows for IDs from 11076 to 15400 \n",
    "    (inclusive).\n",
    "      \n",
    "    Returns\n",
    "    -------------\n",
    "    output: pandas DataFrame\n",
    "        DataFrame sorted by ID as index. Only contains IDs from 11076 to 15400\n",
    "        for columns name, summary, space, and description\n",
    "    '''\n",
    "    \n",
    "    df6 = pd.read_csv('/mnt/data/public/insideairbnb/data.insideairbnb.com/united'\n",
    "                  '-kingdom/england/london/2015-04-06/data/listings.csv.gz')\n",
    "    output = df6[['id','name','summary','space','description']]\n",
    "    output = output[(11076<= output['id']) & (output['id']<=15400)].sort_values(by = 'id')\n",
    "    output.index = output['id']\n",
    "    del output['id']\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>space</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11076</th>\n",
       "      <td>The Sanctury</td>\n",
       "      <td>The room has a double bed and a single foldawa...</td>\n",
       "      <td>This Listing is for The Sanctury The accommoda...</td>\n",
       "      <td>The room has a double bed and a single foldawa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11551</th>\n",
       "      <td>The bright London flat</td>\n",
       "      <td>This flat is located in the trendy neighbor of...</td>\n",
       "      <td>Important!! If you are two travelers or three ...</td>\n",
       "      <td>This flat is located in the trendy neighbor of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11816</th>\n",
       "      <td>Modern Two Bedroom in Knightsbridge</td>\n",
       "      <td>Its all about the (email hidden)tuated at Park...</td>\n",
       "      <td>Situated at London's most exclusive address, K...</td>\n",
       "      <td>Its all about the (email hidden)tuated at Park...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13913</th>\n",
       "      <td>Holiday London DB Room Let-on going</td>\n",
       "      <td>My bright double bedroom with a large window h...</td>\n",
       "      <td>Hello Everyone, I'm offering my lovely double ...</td>\n",
       "      <td>My bright double bedroom with a large window h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15400</th>\n",
       "      <td>Bright Chelsea  Apartment. Chelsea!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bright Chelsea Apartment  This is a bright one...</td>\n",
       "      <td>Bright Chelsea Apartment  This is a bright one...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      name  \\\n",
       "id                                           \n",
       "11076                         The Sanctury   \n",
       "11551               The bright London flat   \n",
       "11816  Modern Two Bedroom in Knightsbridge   \n",
       "13913  Holiday London DB Room Let-on going   \n",
       "15400  Bright Chelsea  Apartment. Chelsea!   \n",
       "\n",
       "                                                 summary  \\\n",
       "id                                                         \n",
       "11076  The room has a double bed and a single foldawa...   \n",
       "11551  This flat is located in the trendy neighbor of...   \n",
       "11816  Its all about the (email hidden)tuated at Park...   \n",
       "13913  My bright double bedroom with a large window h...   \n",
       "15400                                                NaN   \n",
       "\n",
       "                                                   space  \\\n",
       "id                                                         \n",
       "11076  This Listing is for The Sanctury The accommoda...   \n",
       "11551  Important!! If you are two travelers or three ...   \n",
       "11816  Situated at London's most exclusive address, K...   \n",
       "13913  Hello Everyone, I'm offering my lovely double ...   \n",
       "15400  Bright Chelsea Apartment  This is a bright one...   \n",
       "\n",
       "                                             description  \n",
       "id                                                        \n",
       "11076  The room has a double bed and a single foldawa...  \n",
       "11551  This flat is located in the trendy neighbor of...  \n",
       "11816  Its all about the (email hidden)tuated at Park...  \n",
       "13913  My bright double bedroom with a large window h...  \n",
       "15400  Bright Chelsea Apartment  This is a bright one...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T23:19:50.760577Z",
     "start_time": "2021-05-14T23:19:49.818334Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a5d1a62f43835c4004f0ff0cb310817",
     "grade": true,
     "grade_id": "cell-2630ff4dbb9264cc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df_listing = listing_info()\n",
    "assert_equal(isinstance(df_listing, pd.DataFrame), True)\n",
    "assert_array_equal(\n",
    "    df_listing.columns, \n",
    "    ['name', 'summary', 'space', 'description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "499547ea656f26f44f091c9f370b9796",
     "grade": false,
     "grade_id": "cell-c3615a55e1b109b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problem 7\n",
    "Create a function `aisle_dep` that reads `/mnt/data/public/instacart/instacart_2017_05_01/products.csv` and returns a `pandas` `DataFrame`. The index of the data frame should be `product_id`. For products that are found in aisle 5, append the `aisle_id` and `department_id` following the format (`aisle_id`-`department_id`) to the `product_name`. For example, if product `foo` is in aisle 5 and department 6, then the product name should be `foo (5-6)`. Products in the other aisles should be unmodified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T23:20:11.618634Z",
     "start_time": "2021-05-14T23:20:11.613753Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c01249d05b8d97d92eac152c89fead31",
     "grade": false,
     "grade_id": "cell-43465bed9a336adc",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def aisle_dep():\n",
    "    '''reads /mnt/data/public/instacart/instacart_2017_05_01/products.csv and \n",
    "    returns a pandas DataFrame. The index of the data frame is be product_id.\n",
    "    The product name contains the product name and the aisle and department id\n",
    "    if the product is found in aisle 5. \n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    output: pandas DataFrame \n",
    "        DataFrame with index from product_id column values. The aisle and\n",
    "        departmend id of products from aisle 5 are appended with the \n",
    "        corresponding values of its product_name column values\n",
    "    \n",
    "    '''\n",
    "    df7 = pd.read_csv('/mnt/data/public/instacart/instacart_'\n",
    "                      +'2017_05_01/products.csv')\n",
    "    df7.head()\n",
    "    new_S_prod_name = df7['product_name'].astype(str) + ' ' + df7['aisle_id'].astype(str)\\\n",
    "    + '-' + df7['department_id'].astype(str)\n",
    "    new_S_prod_name.name = 'product_name'\n",
    "    new_df7 = pd.DataFrame(new_S_prod_name)\n",
    "    new_df7\n",
    "\n",
    "    df7.update(new_df7)\n",
    "    df7.index = df7['product_id']\n",
    "    del df7['product_id']\n",
    "    final_df7 = df7\n",
    "\n",
    "    return final_df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T23:20:30.396618Z",
     "start_time": "2021-05-14T23:20:30.307675Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a785173c061c546160e569cc3a591ed6",
     "grade": true,
     "grade_id": "cell-26a320d2a7ba5d95",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df_aisle_dep = aisle_dep()\n",
    "assert_equal(isinstance(df_aisle_dep, pd.DataFrame), True)\n",
    "assert_array_equal(\n",
    "    df_aisle_dep.columns, ['product_name', 'aisle_id', 'department_id'])\n",
    "assert_array_equal(\n",
    "    df_aisle_dep.index, np.arange(1, 49689))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8993be98b6afd4974189cec3b2160285",
     "grade": false,
     "grade_id": "cell-cf84a715bc6a632d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problem 8\n",
    "Create a function `camsur_reps` that reads `/mnt/data/public/elections/comelec/congress_results/congressional_results_2013.csv` and returns a `pandas` `DataFrame` with two columns: `surname` and `votes_obtained`. The `surname` is derived from the `name` column. The data frame should only contain those with `province_or_city` equal to `Camarines Sur`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T23:21:31.687945Z",
     "start_time": "2021-05-14T23:21:31.682467Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40a545f74da0d7155e4c29f091351606",
     "grade": false,
     "grade_id": "cell-a99e844ac6350b21",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def camsur_reps():\n",
    "    ''' reads /mnt/data/public/elections/comelec/congress_results/\n",
    "    congressional_results_2013.csv and returns a pandas DataFrame with two \n",
    "    columns: surname and votes_obtained. The surname is derived from the name \n",
    "    column. The data frame should only contain those with province_or_city \n",
    "    equal to Camarines Sur.\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    output: pandas DataFrame \n",
    "        DataFrame with two columns: surname and votes_obtained. \n",
    "        The surname is derived from the name column. The data frame should \n",
    "        only contain those with province_or_city equal to Camarines Sur.\n",
    "    \n",
    "    '''\n",
    "    df8 = pd.read_csv('/mnt/data/public/elections/comelec/'\n",
    "                      +'congress_results/congressional_results_2013.csv')\n",
    "\n",
    "    name_list = df8.name.str.split(',').to_list()\n",
    "    surname_series = pd.Series([i[0] for i in name_list], name = 'surname')\n",
    "    surname_series\n",
    "\n",
    "    df8['surname'] = surname_series\n",
    "    output = df8[df8['province_or_city'] == 'Camarines Sur']\\\n",
    "        [['surname','votes_obtained']]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T23:22:42.478848Z",
     "start_time": "2021-05-14T23:22:42.458547Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6eaa336e5705408413df412d18e35581",
     "grade": true,
     "grade_id": "cell-11852240ddd7095a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df_camsur = camsur_reps()\n",
    "assert_equal(isinstance(df_camsur, pd.DataFrame), True)\n",
    "assert_array_equal(df_camsur.columns, ['surname', 'votes_obtained'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7e552eb9d23497dbdfbcfcbab5ec516",
     "grade": false,
     "grade_id": "cell-7510e5c6231e34d5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problem 9\n",
    "Create a function `no_pop` that reads `/mnt/data/public/millionsong/AdditionalFiles/tracks_per_year.txt` and returns a `pandas` `DataFrame` with columns `year`, `track_id`, `artist` and `title`. It should not include songs from the year 2000 or later, or by artists named `Britney Spears` or `Backstreet Boys`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T23:23:01.584628Z",
     "start_time": "2021-05-14T23:23:01.578574Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1a1d70595efb1d031bef1e4e1291f87",
     "grade": false,
     "grade_id": "cell-e6da009c143aec99",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def no_pop():\n",
    "    ''' reads /mnt/data/public/millionsong/AdditionalFiles/tracks_per_year.txt\n",
    "    and returns a pandas DataFrame with columns year, track_id, artist and \n",
    "    title. It does not include songs from the year 2000 or later, or by \n",
    "    artists named Britney Spears or Backstreet Boys.\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    output: pandas DataFrame \n",
    "        DataFrame which contains columns year, track_id, artist and title. It \n",
    "        excludes songs from the year 2000 or later, or by artists named \n",
    "        Britney Spears or Backstreet Boys.\n",
    "    \n",
    "    '''\n",
    "    with open('/mnt/data/public/millionsong/AdditionalFiles'\n",
    "              +'/tracks_per_year.txt','r') as f:\n",
    "        text = f.readlines()\n",
    "\n",
    "    #len(text)  515576 lines\n",
    "\n",
    "    li = [i.split('<SEP>') for i in text]\n",
    "    \n",
    "    year_S = pd.Series([i[0] for i in li])\n",
    "    \n",
    "    trackid_S = pd.Series([i[1] for i in li])\n",
    "    \n",
    "    artist_S = pd.Series([i[2] for i in li])\n",
    "    \n",
    "    title_S = pd.Series([i[3][:-1] for i in li])  \n",
    "    \n",
    "    df_cols = [('year',year_S), ('track_id',trackid_S), \\\n",
    "               ('artist', artist_S), ('title', title_S)]\n",
    "    \n",
    "    df9 = pd.DataFrame()\n",
    "\n",
    "    for col in df_cols:\n",
    "        df9[col[0]] = col[1]\n",
    "\n",
    "    output = df9[df9['year'].astype(int) < 2000]\n",
    "    output = output[(output['artist'] != 'Britney Spears') & (output['artist'] != 'Backstreet Boys')]\n",
    "  \n",
    "    \n",
    "\n",
    "#     output = df9[(df9['year'].astype(int) > 2000) & \\\n",
    "#                  ~(df9['artist'] == 'Britney Spears') & ~(df9['artist'] \\\n",
    "#                                                         == 'Backstreet Boys')]\n",
    "    return output\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1922</td>\n",
       "      <td>TRSGHLU128F421DF83</td>\n",
       "      <td>Alberta Hunter</td>\n",
       "      <td>Don't Pan Me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1922</td>\n",
       "      <td>TRMYDFV128F42511FC</td>\n",
       "      <td>Barrington Levy</td>\n",
       "      <td>Warm And Sunny Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1922</td>\n",
       "      <td>TRRAHXQ128F42511FF</td>\n",
       "      <td>Barrington Levy</td>\n",
       "      <td>Looking My Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1922</td>\n",
       "      <td>TRFAFTK12903CC77B8</td>\n",
       "      <td>Barrington Levy</td>\n",
       "      <td>Warm And Sunny Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1922</td>\n",
       "      <td>TRSTBUY128F4251203</td>\n",
       "      <td>Barrington Levy</td>\n",
       "      <td>Mandela You're Free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207056</th>\n",
       "      <td>1999</td>\n",
       "      <td>TRZTTVE128F42A9922</td>\n",
       "      <td>üNN</td>\n",
       "      <td>There's Some Truth It</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207057</th>\n",
       "      <td>1999</td>\n",
       "      <td>TRPJQXK128F42A993C</td>\n",
       "      <td>üNN</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207058</th>\n",
       "      <td>1999</td>\n",
       "      <td>TRTYTEL128F42A9956</td>\n",
       "      <td>üNN</td>\n",
       "      <td>Arrival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207059</th>\n",
       "      <td>1999</td>\n",
       "      <td>TRUFRVS128F42A9965</td>\n",
       "      <td>üNN</td>\n",
       "      <td>As Cs Ds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207060</th>\n",
       "      <td>1999</td>\n",
       "      <td>TREXENR128F42A991A</td>\n",
       "      <td>üNN</td>\n",
       "      <td>Just For A Minute</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207001 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year            track_id           artist                  title\n",
       "0       1922  TRSGHLU128F421DF83   Alberta Hunter           Don't Pan Me\n",
       "1       1922  TRMYDFV128F42511FC  Barrington Levy     Warm And Sunny Day\n",
       "2       1922  TRRAHXQ128F42511FF  Barrington Levy        Looking My Love\n",
       "3       1922  TRFAFTK12903CC77B8  Barrington Levy     Warm And Sunny Day\n",
       "4       1922  TRSTBUY128F4251203  Barrington Levy    Mandela You're Free\n",
       "...      ...                 ...              ...                    ...\n",
       "207056  1999  TRZTTVE128F42A9922              üNN  There's Some Truth It\n",
       "207057  1999  TRPJQXK128F42A993C              üNN                   Blue\n",
       "207058  1999  TRTYTEL128F42A9956              üNN                Arrival\n",
       "207059  1999  TRUFRVS128F42A9965              üNN               As Cs Ds\n",
       "207060  1999  TREXENR128F42A991A              üNN      Just For A Minute\n",
       "\n",
       "[207001 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows with years 2000 and later = 226354\n",
    "# rows of df9 == 515576\n",
    "# rows with britney spears = 145\n",
    "# rows with backstreet boys = 105\n",
    "no_pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T23:37:11.355794Z",
     "start_time": "2021-05-14T23:37:08.945304Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bbb7032d8c6ca00f42f0de86b8d53f6e",
     "grade": true,
     "grade_id": "cell-e7a30e01a581c4d3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df_nopop = no_pop()\n",
    "assert_equal(isinstance(df_nopop, pd.DataFrame), True)\n",
    "assert_array_equal(df_nopop.columns, ['year', 'track_id', 'artist', 'title'])\n",
    "assert_equal(df_nopop.shape, (207001, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da3ae3013b8d8442587fe76cd7ac7757",
     "grade": false,
     "grade_id": "cell-6305d5a8b54402d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problem 10\n",
    "Create the functions `read_trips` and `write_trips`. The `read_trips` function should read `/mnt/data/public/nyctaxi/trip_data/trip_data_1.csv` and return a `pandas` `DataFrame` which contains the contents of the first 100 data rows of the CSV file. The type of `rate_code` should be `str`, and `pickup_datetime` and `dropoff_datetime` should be `datetime`. The `write_trips` function should accept the output of `read_trips` and save the columns `pickup_longitude`,\t`pickup_latitude`, `dropoff_longitude`, and `dropoff_latitude` to a CSV file named `trip_coords.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T02:49:16.090688Z",
     "start_time": "2020-03-31T02:49:16.082886Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3aab8f1a5bcb08147c5543449950006",
     "grade": false,
     "grade_id": "cell-f87962d94e14bc63",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def read_trips():\n",
    "    '''reads /mnt/data/public/nyctaxi/trip_data/trip_data_1.csv and returns a \n",
    "    pandas DataFrame which contains the contents of the first 100 data rows \n",
    "    of the CSV file. The type of rate_code should be str, and pickup_datetime\n",
    "    and dropoff_datetime should be datetime.\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    df_trips_10: pandas DataFrame \n",
    "        DataFrame which contains the contents of the first 100 data rows \n",
    "        of the CSV file. The type of rate_code is object, and \n",
    "        pickup_datetime and dropoff_datetime are datetime.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    df_trips_10 = pd.read_csv('/mnt/data/public/nyctaxi/trip_data/trip_data_1.csv').head(100)\n",
    "    df_trips_10['rate_code'] = df_trips_10['rate_code'].astype(str)\n",
    "    df_trips_10['pickup_datetime'] = pd.to_datetime(df_trips_10['pickup_datetime'])\n",
    "    df_trips_10['dropoff_datetime'] = pd.to_datetime(df_trips_10['pickup_datetime'])\n",
    "    return df_trips_10\n",
    "\n",
    "def write_trips(df_trips):\n",
    "    '''accepts the output of read_trips and save the columns pickup_longitude,\n",
    "    pickup_latitude, dropoff_longitude, and dropoff_latitude to a CSV file \n",
    "    named trip_coords.csv.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    df_trips: pandas DataFrame\n",
    "        output of read_trips function     \n",
    "    '''\n",
    "    df_write_trips = df_trips[['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude']]\n",
    "    df_write_trips.to_csv('trip_coords.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T23:40:04.947775Z",
     "start_time": "2021-05-14T23:40:04.187127Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "916f30d6c5888b4846190d6d156db661",
     "grade": true,
     "grade_id": "cell-27830b8e96add27d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!rm -f trip_coords.csv\n",
    "df_trips = read_trips()\n",
    "write_trips(df_trips)\n",
    "assert_equal(isinstance(df_trips, pd.DataFrame), True)\n",
    "assert_array_equal(df_trips.shape, (100, 14))\n",
    "assert_array_equal(\n",
    "    df_trips.columns, \n",
    "    ['medallion', 'hack_license', 'vendor_id', 'rate_code', \n",
    "     'store_and_fwd_flag', 'pickup_datetime', 'dropoff_datetime',\n",
    "     'passenger_count', 'trip_time_in_secs', 'trip_distance', \n",
    "     'pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
    "     'dropoff_latitude'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
